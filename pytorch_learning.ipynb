{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e49a23-81e9-4dea-8d56-3f5ef77b0244",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version 1.13.1\n",
      "Device = cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"torch version {torch.__version__}\")\n",
    "from torch import nn\n",
    "import datetime\n",
    "\n",
    "# Importing TensorBoard libraries for visuvalization\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Importing Ray Tune libraries for hyperparameter tuning\n",
    "from ray import train, tune\n",
    "\n",
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "print(f\"Device = {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5b1c65-e147-4e45-bdf7-5d12abb80112",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "runs/pytoch_learning/20231024-200502\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1.], [2.], [3.], [4.], [5.], [6.], [7.], [8.], [9.], [10.]])\n",
    "y = torch.tensor([[2.], [4.], [6.], [8.], [10.], [12.], [14.], [16.], [18.], [20.]])\n",
    "#X_test = torch.tensor([[2.5], [22.], [-6.], [.25],])\n",
    "#y_test = torch.tensor([[5.], [44.], [-12.], [.5],])\n",
    "X_test = torch.tensor([[40.]])\n",
    "y_test = torch.tensor([[80.]])\n",
    "print(X.size())\n",
    "print(y.size())\n",
    "print(X_test.size())\n",
    "print(y_test.size())\n",
    "\n",
    "tboard_dir = \"runs/pytoch_learning/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\");\n",
    "print(tboard_dir)\n",
    "writer = SummaryWriter(tboard_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399d58ab-f276-4559-a9de-8ab300cb9e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None, target_transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d8a79c-fda0-4951-8423-e24f373d6745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_dataset = MyDataset(X,y)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [8, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e9e1b6f-e061-43f6-8f3c-f2a412169025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93513d9c-1cbc-4ab6-94da-786e751fb7c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_stack.weight | Size: torch.Size([1, 1]) | Values : tensor([[0.5638]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_stack.bias | Size: torch.Size([1]) | Values : tensor([0.2933], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_stack = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork()\n",
    "#print(f\"Model structure : {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de722f31-55f9-4c66-9079-5a560fb0cfc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        #print(f\"Batch = {batch}\")\n",
    "        #print(f\"X = {X}\")\n",
    "        #print(f\"y = {y}\")\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # parameters after optimization\n",
    "        #print(\"**** parms after optimizer ****\")\n",
    "        #for name, param in model.named_parameters():\n",
    "        #    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]}\")\n",
    "        #print(\"\\n\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            #print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e96d586f-a571-4864-8af4-7df854030dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    #print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21012483-f76b-45eb-b2a3-1e2d57b3cbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function : MSELoss() \n",
      "\n",
      "Optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#learning_rate = 1e-3\n",
    "learning_rate = 0.01\n",
    "batch_size = 2\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "print(f\"Loss function : {loss_fn} \\n\")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "print(f\"Optimizer : {optimizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d05546-e090-4d05-895b-0b8ea86d8cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Weight = 1.8211802244186401, Bias = 0.45981237292289734, Training Loss = 87.85010528564453, Testing Loss = 0.035569079453125596\n",
      "Epoch 2, Weight = 1.9269405603408813, Bias = 0.4720745086669922, Training Loss = 0.6636887788772583, Testing Loss = 0.04814881458878517\n",
      "Epoch 3, Weight = 1.9360451698303223, Bias = 0.4714001417160034, Training Loss = 0.049176041036844254, Testing Loss = 0.0623076930642128\n",
      "Epoch 4, Weight = 1.9370365142822266, Bias = 0.46964672207832336, Training Loss = 0.04449833929538727, Testing Loss = 0.06312888860702515\n",
      "Epoch 5, Weight = 1.93734610080719, Bias = 0.46780940890312195, Training Loss = 0.04411894828081131, Testing Loss = 0.06274387612938881\n",
      "Epoch 6, Weight = 1.937597393989563, Bias = 0.4659716784954071, Training Loss = 0.043772630393505096, Testing Loss = 0.06226067245006561\n",
      "Epoch 7, Weight = 1.9378430843353271, Bias = 0.46414056420326233, Training Loss = 0.04342930018901825, Testing Loss = 0.06177313253283501\n",
      "Epoch 8, Weight = 1.9380874633789062, Bias = 0.4623165726661682, Training Loss = 0.0430886372923851, Testing Loss = 0.06128877028822899\n",
      "Epoch 9, Weight = 1.9383307695388794, Bias = 0.46049973368644714, Training Loss = 0.04275060072541237, Testing Loss = 0.0608079768717289\n",
      "Epoch 10, Weight = 1.9385731220245361, Bias = 0.4586900472640991, Training Loss = 0.04241529107093811, Testing Loss = 0.0603310652077198\n",
      "Epoch 11, Weight = 1.9388145208358765, Bias = 0.45688748359680176, Training Loss = 0.042082492262125015, Testing Loss = 0.05985775589942932\n",
      "Epoch 12, Weight = 1.9390549659729004, Bias = 0.4550919830799103, Training Loss = 0.04175235703587532, Testing Loss = 0.05938833951950073\n",
      "Epoch 13, Weight = 1.939294457435608, Bias = 0.4533035457134247, Training Loss = 0.04142501577734947, Testing Loss = 0.058922410011291504\n",
      "Epoch 14, Weight = 1.939532995223999, Bias = 0.4515221416950226, Training Loss = 0.04109994322061539, Testing Loss = 0.05846007168292999\n",
      "Epoch 15, Weight = 1.9397705793380737, Bias = 0.4497477412223816, Training Loss = 0.04077751189470291, Testing Loss = 0.058001380413770676\n",
      "Epoch 16, Weight = 1.9400073289871216, Bias = 0.4479803144931793, Training Loss = 0.04045778512954712, Testing Loss = 0.057546695694327354\n",
      "Epoch 17, Weight = 1.940243124961853, Bias = 0.4462198317050934, Training Loss = 0.04014028236269951, Testing Loss = 0.057095279917120934\n",
      "Epoch 18, Weight = 1.940477967262268, Bias = 0.4444662630558014, Training Loss = 0.03982539474964142, Testing Loss = 0.05664737708866596\n",
      "Epoch 19, Weight = 1.9407118558883667, Bias = 0.44271957874298096, Training Loss = 0.03951314836740494, Testing Loss = 0.05620303191244602\n",
      "Epoch 20, Weight = 1.940944790840149, Bias = 0.4409797787666321, Training Loss = 0.03920311853289604, Testing Loss = 0.05576208233833313\n",
      "Epoch 21, Weight = 1.9411768913269043, Bias = 0.43924680352211, Training Loss = 0.038895659148693085, Testing Loss = 0.05532472021877766\n",
      "Epoch 22, Weight = 1.9414080381393433, Bias = 0.4375206232070923, Training Loss = 0.038590483367443085, Testing Loss = 0.05489059165120125\n",
      "Epoch 23, Weight = 1.9416383504867554, Bias = 0.435801237821579, Training Loss = 0.03828784078359604, Testing Loss = 0.054460061714053154\n",
      "Epoch 24, Weight = 1.941867709159851, Bias = 0.4340886175632477, Training Loss = 0.037987519055604935, Testing Loss = 0.05403292179107666\n",
      "Epoch 25, Weight = 1.94209623336792, Bias = 0.432382732629776, Training Loss = 0.03768955171108246, Testing Loss = 0.0536092147231102\n",
      "Epoch 26, Weight = 1.9423236846923828, Bias = 0.43068352341651917, Training Loss = 0.037393808364868164, Testing Loss = 0.05318853817880154\n",
      "Epoch 27, Weight = 1.9425504207611084, Bias = 0.42899101972579956, Training Loss = 0.03710053116083145, Testing Loss = 0.05277144908905029\n",
      "Epoch 28, Weight = 1.942776083946228, Bias = 0.42730513215065, Training Loss = 0.03680945187807083, Testing Loss = 0.05235728621482849\n",
      "Epoch 29, Weight = 1.9430009126663208, Bias = 0.42562589049339294, Training Loss = 0.036520712077617645, Testing Loss = 0.051946673542261124\n",
      "Epoch 30, Weight = 1.9432249069213867, Bias = 0.42395326495170593, Training Loss = 0.03623420000076294, Testing Loss = 0.05153901316225529\n",
      "Epoch 31, Weight = 1.9434480667114258, Bias = 0.4222871959209442, Training Loss = 0.0359499529004097, Testing Loss = 0.05113479495048523\n",
      "Epoch 32, Weight = 1.943670392036438, Bias = 0.4206276834011078, Training Loss = 0.03566804900765419, Testing Loss = 0.05073399469256401\n",
      "Epoch 33, Weight = 1.9438916444778442, Bias = 0.4189746677875519, Training Loss = 0.03538823872804642, Testing Loss = 0.05033579096198082\n",
      "Epoch 34, Weight = 1.9441121816635132, Bias = 0.4173281788825989, Training Loss = 0.03511068969964981, Testing Loss = 0.04994103126227856\n",
      "Epoch 35, Weight = 1.9443318843841553, Bias = 0.415688157081604, Training Loss = 0.034835245460271835, Testing Loss = 0.04954932816326618\n",
      "Epoch 36, Weight = 1.944550633430481, Bias = 0.4140545725822449, Training Loss = 0.034562017768621445, Testing Loss = 0.04916059598326683\n",
      "Epoch 37, Weight = 1.9447684288024902, Bias = 0.4124273955821991, Training Loss = 0.034290868788957596, Testing Loss = 0.04877476766705513\n",
      "Epoch 38, Weight = 1.9449855089187622, Bias = 0.4108066260814667, Training Loss = 0.034021809697151184, Testing Loss = 0.04839223995804787\n",
      "Epoch 39, Weight = 1.9452017545700073, Bias = 0.4091922342777252, Training Loss = 0.03375498950481415, Testing Loss = 0.048012761399149895\n",
      "Epoch 40, Weight = 1.9454171657562256, Bias = 0.40758419036865234, Training Loss = 0.03349021077156067, Testing Loss = 0.047636184841394424\n",
      "Epoch 41, Weight = 1.9456316232681274, Bias = 0.40598243474960327, Training Loss = 0.03322751820087433, Testing Loss = 0.04726255498826504\n",
      "Epoch 42, Weight = 1.9458452463150024, Bias = 0.4043869972229004, Training Loss = 0.03296681120991707, Testing Loss = 0.04689174145460129\n",
      "Epoch 43, Weight = 1.9460581541061401, Bias = 0.4027978181838989, Training Loss = 0.032708317041397095, Testing Loss = 0.04652402177453041\n",
      "Epoch 44, Weight = 1.9462701082229614, Bias = 0.4012148976325989, Training Loss = 0.032451748847961426, Testing Loss = 0.046159133315086365\n",
      "Epoch 45, Weight = 1.9464812278747559, Bias = 0.39963817596435547, Training Loss = 0.03219713270664215, Testing Loss = 0.045796897262334824\n",
      "Epoch 46, Weight = 1.9466915130615234, Bias = 0.3980676531791687, Training Loss = 0.031944550573825836, Testing Loss = 0.0454375259578228\n",
      "Epoch 47, Weight = 1.9469010829925537, Bias = 0.3965033292770386, Training Loss = 0.03169400617480278, Testing Loss = 0.04508128948509693\n",
      "Epoch 48, Weight = 1.9471096992492676, Bias = 0.3949451446533203, Training Loss = 0.031445372849702835, Testing Loss = 0.044727593660354614\n",
      "Epoch 49, Weight = 1.9473176002502441, Bias = 0.39339306950569153, Training Loss = 0.031198760494589806, Testing Loss = 0.044376885518431664\n",
      "Epoch 50, Weight = 1.9475246667861938, Bias = 0.3918471038341522, Training Loss = 0.03095407597720623, Testing Loss = 0.04402879998087883\n",
      "Epoch 51, Weight = 1.9477308988571167, Bias = 0.39030721783638, Training Loss = 0.030711136758327484, Testing Loss = 0.043683381751179695\n",
      "Epoch 52, Weight = 1.9479362964630127, Bias = 0.3887733817100525, Training Loss = 0.030470367521047592, Testing Loss = 0.04334072582423687\n",
      "Epoch 53, Weight = 1.9481408596038818, Bias = 0.3872455656528473, Training Loss = 0.030231287702918053, Testing Loss = 0.0430005993694067\n",
      "Epoch 54, Weight = 1.9483447074890137, Bias = 0.3857237696647644, Training Loss = 0.029994122684001923, Testing Loss = 0.04266348481178284\n",
      "Epoch 55, Weight = 1.948547601699829, Bias = 0.38420793414115906, Training Loss = 0.029758866876363754, Testing Loss = 0.04232863523066044\n",
      "Epoch 56, Weight = 1.9487497806549072, Bias = 0.38269805908203125, Training Loss = 0.029525382444262505, Testing Loss = 0.041996654123067856\n",
      "Epoch 57, Weight = 1.948951244354248, Bias = 0.3811941146850586, Training Loss = 0.029293837025761604, Testing Loss = 0.04166724905371666\n",
      "Epoch 58, Weight = 1.9491517543792725, Bias = 0.3796960711479187, Training Loss = 0.02906394749879837, Testing Loss = 0.04134012758731842\n",
      "Epoch 59, Weight = 1.9493516683578491, Bias = 0.3782039284706116, Training Loss = 0.02883601002395153, Testing Loss = 0.04101604409515858\n",
      "Epoch 60, Weight = 1.9495506286621094, Bias = 0.3767176568508148, Training Loss = 0.028609860688447952, Testing Loss = 0.040694212540984154\n",
      "Epoch 61, Weight = 1.9497488737106323, Bias = 0.37523722648620605, Training Loss = 0.028385361656546593, Testing Loss = 0.04037489742040634\n",
      "Epoch 62, Weight = 1.9499465227127075, Bias = 0.3737626373767853, Training Loss = 0.028162825852632523, Testing Loss = 0.04005856812000275\n",
      "Epoch 63, Weight = 1.9501430988311768, Bias = 0.3722938001155853, Training Loss = 0.027941914275288582, Testing Loss = 0.039744178764522076\n",
      "Epoch 64, Weight = 1.9503390789031982, Bias = 0.3708307445049286, Training Loss = 0.02772267535328865, Testing Loss = 0.03943232074379921\n",
      "Epoch 65, Weight = 1.9505342245101929, Bias = 0.3693734407424927, Training Loss = 0.027505189180374146, Testing Loss = 0.03912312816828489\n",
      "Epoch 66, Weight = 1.9507286548614502, Bias = 0.3679218590259552, Training Loss = 0.027289455756545067, Testing Loss = 0.03881631884723902\n",
      "Epoch 67, Weight = 1.9509222507476807, Bias = 0.3664759695529938, Training Loss = 0.027075381949543953, Testing Loss = 0.03851183131337166\n",
      "Epoch 68, Weight = 1.9511151313781738, Bias = 0.3650357723236084, Training Loss = 0.02686302550137043, Testing Loss = 0.038209653459489346\n",
      "Epoch 69, Weight = 1.9513071775436401, Bias = 0.3636012375354767, Training Loss = 0.026652317494153976, Testing Loss = 0.03790981508791447\n",
      "Epoch 70, Weight = 1.9514985084533691, Bias = 0.36217233538627625, Training Loss = 0.026443250477313995, Testing Loss = 0.0376123646274209\n",
      "Epoch 71, Weight = 1.9516891241073608, Bias = 0.3607490658760071, Training Loss = 0.02623574808239937, Testing Loss = 0.03731738682836294\n",
      "Epoch 72, Weight = 1.9518790245056152, Bias = 0.3593313992023468, Training Loss = 0.026030011475086212, Testing Loss = 0.03702476527541876\n",
      "Epoch 73, Weight = 1.9520680904388428, Bias = 0.35791927576065063, Training Loss = 0.025825783610343933, Testing Loss = 0.03673428203910589\n",
      "Epoch 74, Weight = 1.952256441116333, Bias = 0.35651272535324097, Training Loss = 0.025623181834816933, Testing Loss = 0.03644617460668087\n",
      "Epoch 75, Weight = 1.952444076538086, Bias = 0.355111688375473, Training Loss = 0.025422267615795135, Testing Loss = 0.03616027906537056\n",
      "Epoch 76, Weight = 1.9526309967041016, Bias = 0.3537161648273468, Training Loss = 0.025222789496183395, Testing Loss = 0.035876630805432796\n",
      "Epoch 77, Weight = 1.9528172016143799, Bias = 0.3523261249065399, Training Loss = 0.025024959817528725, Testing Loss = 0.03559532668441534\n",
      "Epoch 78, Weight = 1.9530025720596313, Bias = 0.35094153881073, Training Loss = 0.024828685447573662, Testing Loss = 0.035315985791385174\n",
      "Epoch 79, Weight = 1.953187346458435, Bias = 0.349562406539917, Training Loss = 0.024633942171931267, Testing Loss = 0.035039061680436134\n",
      "Epoch 80, Weight = 1.953371286392212, Bias = 0.3481886684894562, Training Loss = 0.024440689012408257, Testing Loss = 0.034764232113957405\n",
      "Epoch 81, Weight = 1.9535545110702515, Bias = 0.3468203544616699, Training Loss = 0.024248965084552765, Testing Loss = 0.034491440281271935\n",
      "Epoch 82, Weight = 1.9537370204925537, Bias = 0.34545740485191345, Training Loss = 0.02405869960784912, Testing Loss = 0.034220815636217594\n",
      "Epoch 83, Weight = 1.9539188146591187, Bias = 0.34409981966018677, Training Loss = 0.023869981989264488, Testing Loss = 0.03395240381360054\n",
      "Epoch 84, Weight = 1.9540998935699463, Bias = 0.3427475690841675, Training Loss = 0.023682788014411926, Testing Loss = 0.03368618618696928\n",
      "Epoch 85, Weight = 1.9542803764343262, Bias = 0.3414006233215332, Training Loss = 0.023497050628066063, Testing Loss = 0.03342190384864807\n",
      "Epoch 86, Weight = 1.9544600248336792, Bias = 0.34005895256996155, Training Loss = 0.023312661796808243, Testing Loss = 0.03315969556570053\n",
      "Epoch 87, Weight = 1.954638957977295, Bias = 0.3387225568294525, Training Loss = 0.023129818961024284, Testing Loss = 0.032899593003094196\n",
      "Epoch 88, Weight = 1.9548171758651733, Bias = 0.3373914361000061, Training Loss = 0.022948337718844414, Testing Loss = 0.032641444355249405\n",
      "Epoch 89, Weight = 1.9549946784973145, Bias = 0.33606553077697754, Training Loss = 0.02276839129626751, Testing Loss = 0.032385378144681454\n",
      "Epoch 90, Weight = 1.9551717042922974, Bias = 0.3347448706626892, Training Loss = 0.02258976176381111, Testing Loss = 0.03213157970458269\n",
      "Epoch 91, Weight = 1.9553477764129639, Bias = 0.33342936635017395, Training Loss = 0.02241247147321701, Testing Loss = 0.0318793086335063\n",
      "Epoch 92, Weight = 1.9555232524871826, Bias = 0.33211904764175415, Training Loss = 0.02223673090338707, Testing Loss = 0.031629230827093124\n",
      "Epoch 93, Weight = 1.955698013305664, Bias = 0.3308138847351074, Training Loss = 0.02206229791045189, Testing Loss = 0.031381238251924515\n",
      "Epoch 94, Weight = 1.9558720588684082, Bias = 0.3295138478279114, Training Loss = 0.021889247000217438, Testing Loss = 0.03113493137061596\n",
      "Epoch 95, Weight = 1.9560456275939941, Bias = 0.328218936920166, Training Loss = 0.021717578172683716, Testing Loss = 0.030890831723809242\n",
      "Epoch 96, Weight = 1.9562183618545532, Bias = 0.32692909240722656, Training Loss = 0.021547231823205948, Testing Loss = 0.030648542568087578\n",
      "Epoch 97, Weight = 1.956390380859375, Bias = 0.325644314289093, Training Loss = 0.021378161385655403, Testing Loss = 0.030408195219933987\n",
      "Epoch 98, Weight = 1.956561803817749, Bias = 0.324364572763443, Training Loss = 0.021210523322224617, Testing Loss = 0.030169637873768806\n",
      "Epoch 99, Weight = 1.9567325115203857, Bias = 0.3230898678302765, Training Loss = 0.021044127643108368, Testing Loss = 0.02993295155465603\n",
      "Epoch 100, Weight = 1.9569025039672852, Bias = 0.3218201696872711, Training Loss = 0.020879026502370834, Testing Loss = 0.029698175378143787\n",
      "Epoch 101, Weight = 1.9570719003677368, Bias = 0.3205554783344269, Training Loss = 0.02071530371904373, Testing Loss = 0.029465246945619583\n",
      "Epoch 102, Weight = 1.9572405815124512, Bias = 0.319295734167099, Training Loss = 0.02055278606712818, Testing Loss = 0.029234115965664387\n",
      "Epoch 103, Weight = 1.9574085474014282, Bias = 0.3180409371852875, Training Loss = 0.020391499623656273, Testing Loss = 0.029004720970988274\n",
      "Epoch 104, Weight = 1.9575759172439575, Bias = 0.3167910873889923, Training Loss = 0.020231589674949646, Testing Loss = 0.028777141124010086\n",
      "Epoch 105, Weight = 1.9577425718307495, Bias = 0.3155461549758911, Training Loss = 0.020072877407073975, Testing Loss = 0.028551327995955944\n",
      "Epoch 106, Weight = 1.9579087495803833, Bias = 0.3143061399459839, Training Loss = 0.01991543546319008, Testing Loss = 0.02832749020308256\n",
      "Epoch 107, Weight = 1.9580740928649902, Bias = 0.31307095289230347, Training Loss = 0.0197591632604599, Testing Loss = 0.02810521610081196\n",
      "Epoch 108, Weight = 1.9582388401031494, Bias = 0.31184065341949463, Training Loss = 0.01960420422255993, Testing Loss = 0.02788480743765831\n",
      "Epoch 109, Weight = 1.9584029912948608, Bias = 0.3106151819229126, Training Loss = 0.01945047453045845, Testing Loss = 0.027665982022881508\n",
      "Epoch 110, Weight = 1.958566427230835, Bias = 0.309394508600235, Training Loss = 0.019297834485769272, Testing Loss = 0.027448960579931736\n",
      "Epoch 111, Weight = 1.9587292671203613, Bias = 0.3081786334514618, Training Loss = 0.019146446138620377, Testing Loss = 0.027233680710196495\n",
      "Epoch 112, Weight = 1.95889151096344, Bias = 0.306967556476593, Training Loss = 0.018996329978108406, Testing Loss = 0.027020134963095188\n",
      "Epoch 113, Weight = 1.9590530395507812, Bias = 0.3057612180709839, Training Loss = 0.018847305327653885, Testing Loss = 0.026808183640241623\n",
      "Epoch 114, Weight = 1.9592139720916748, Bias = 0.3045596182346344, Training Loss = 0.018699437379837036, Testing Loss = 0.02659785747528076\n",
      "Epoch 115, Weight = 1.959374189376831, Bias = 0.30336275696754456, Training Loss = 0.0185527466237545, Testing Loss = 0.026389148086309433\n",
      "Epoch 116, Weight = 1.959533929824829, Bias = 0.30217060446739197, Training Loss = 0.01840725541114807, Testing Loss = 0.026182351633906364\n",
      "Epoch 117, Weight = 1.9596929550170898, Bias = 0.30098313093185425, Training Loss = 0.01826287806034088, Testing Loss = 0.025976894423365593\n",
      "Epoch 118, Weight = 1.9598512649536133, Bias = 0.299800306558609, Training Loss = 0.018119540065526962, Testing Loss = 0.02577297668904066\n",
      "Epoch 119, Weight = 1.9600090980529785, Bias = 0.29862216114997864, Training Loss = 0.017977416515350342, Testing Loss = 0.025570901110768318\n",
      "Epoch 120, Weight = 1.960166335105896, Bias = 0.29744863510131836, Training Loss = 0.017836429178714752, Testing Loss = 0.025370395742356777\n",
      "Epoch 121, Weight = 1.9603227376937866, Bias = 0.2962796986103058, Training Loss = 0.017696473747491837, Testing Loss = 0.025171232409775257\n",
      "Epoch 122, Weight = 1.960478663444519, Bias = 0.2951153814792633, Training Loss = 0.017557688057422638, Testing Loss = 0.024973750114440918\n",
      "Epoch 123, Weight = 1.9606341123580933, Bias = 0.29395565390586853, Training Loss = 0.01741999015212059, Testing Loss = 0.024778024293482304\n",
      "Epoch 124, Weight = 1.9607888460159302, Bias = 0.2928004562854767, Training Loss = 0.0172833651304245, Testing Loss = 0.024583744816482067\n",
      "Epoch 125, Weight = 1.9609427452087402, Bias = 0.2916497588157654, Training Loss = 0.017147736623883247, Testing Loss = 0.0243906918913126\n",
      "Epoch 126, Weight = 1.9610962867736816, Bias = 0.2905036211013794, Training Loss = 0.017013249918818474, Testing Loss = 0.024199366569519043\n",
      "Epoch 127, Weight = 1.9612492322921753, Bias = 0.28936198353767395, Training Loss = 0.016879739239811897, Testing Loss = 0.024009673856198788\n",
      "Epoch 128, Weight = 1.9614014625549316, Bias = 0.28822484612464905, Training Loss = 0.016747379675507545, Testing Loss = 0.023821266368031502\n",
      "Epoch 129, Weight = 1.9615532159805298, Bias = 0.2870921790599823, Training Loss = 0.016616009175777435, Testing Loss = 0.023634428158402443\n",
      "Epoch 130, Weight = 1.9617042541503906, Bias = 0.2859639525413513, Training Loss = 0.01648564822971821, Testing Loss = 0.023449032567441463\n",
      "Epoch 131, Weight = 1.9618548154830933, Bias = 0.2848401665687561, Training Loss = 0.01635637693107128, Testing Loss = 0.023265105672180653\n",
      "Epoch 132, Weight = 1.9620046615600586, Bias = 0.28372079133987427, Training Loss = 0.016228098422288895, Testing Loss = 0.023082640953361988\n",
      "Epoch 133, Weight = 1.9621540307998657, Bias = 0.2826058268547058, Training Loss = 0.016100764274597168, Testing Loss = 0.022901548072695732\n",
      "Epoch 134, Weight = 1.9623026847839355, Bias = 0.28149521350860596, Training Loss = 0.01597445085644722, Testing Loss = 0.02272181771695614\n",
      "Epoch 135, Weight = 1.9624507427215576, Bias = 0.2803889811038971, Training Loss = 0.01584906131029129, Testing Loss = 0.02254344429820776\n",
      "Epoch 136, Weight = 1.9625983238220215, Bias = 0.27928709983825684, Training Loss = 0.01572476513683796, Testing Loss = 0.022366702556610107\n",
      "Epoch 137, Weight = 1.9627453088760376, Bias = 0.2781895399093628, Training Loss = 0.015601448714733124, Testing Loss = 0.02219125535339117\n",
      "Epoch 138, Weight = 1.9628918170928955, Bias = 0.27709633111953735, Training Loss = 0.01547911949455738, Testing Loss = 0.022017386741936207\n",
      "Epoch 139, Weight = 1.9630376100540161, Bias = 0.27600738406181335, Training Loss = 0.015357688069343567, Testing Loss = 0.021844515576958656\n",
      "Epoch 140, Weight = 1.963182806968689, Bias = 0.2749227285385132, Training Loss = 0.015237201936542988, Testing Loss = 0.021673161536455154\n",
      "Epoch 141, Weight = 1.9633275270462036, Bias = 0.27384233474731445, Training Loss = 0.015117611736059189, Testing Loss = 0.021503192372620106\n",
      "Epoch 142, Weight = 1.9634716510772705, Bias = 0.2727661728858948, Training Loss = 0.014999101869761944, Testing Loss = 0.021334524266421795\n",
      "Epoch 143, Weight = 1.9636151790618896, Bias = 0.27169424295425415, Training Loss = 0.014881418086588383, Testing Loss = 0.021167070604860783\n",
      "Epoch 144, Weight = 1.9637582302093506, Bias = 0.2706265449523926, Training Loss = 0.014764665625989437, Testing Loss = 0.02100117690861225\n",
      "Epoch 145, Weight = 1.9639006853103638, Bias = 0.2695630192756653, Training Loss = 0.014648878015577793, Testing Loss = 0.02083651628345251\n",
      "Epoch 146, Weight = 1.9640424251556396, Bias = 0.26850366592407227, Training Loss = 0.01453392580151558, Testing Loss = 0.02067289501428604\n",
      "Epoch 147, Weight = 1.9641838073730469, Bias = 0.2674485146999359, Training Loss = 0.014419959858059883, Testing Loss = 0.020510765723884106\n",
      "Epoch 148, Weight = 1.9643245935440063, Bias = 0.26639747619628906, Training Loss = 0.014306832104921341, Testing Loss = 0.020349890924990177\n",
      "Epoch 149, Weight = 1.964464783668518, Bias = 0.2653505802154541, Training Loss = 0.014194607734680176, Testing Loss = 0.02019030461087823\n",
      "Epoch 150, Weight = 1.964604377746582, Bias = 0.26430779695510864, Training Loss = 0.014083275571465492, Testing Loss = 0.02003191551193595\n",
      "Epoch 151, Weight = 1.9647434949874878, Bias = 0.2632691264152527, Training Loss = 0.01397284958511591, Testing Loss = 0.01987468358129263\n",
      "Epoch 152, Weight = 1.9648820161819458, Bias = 0.26223450899124146, Training Loss = 0.013863194733858109, Testing Loss = 0.019718827679753304\n",
      "Epoch 153, Weight = 1.9650200605392456, Bias = 0.26120397448539734, Training Loss = 0.013754463754594326, Testing Loss = 0.019564155023545027\n",
      "Epoch 154, Weight = 1.9651576280593872, Bias = 0.26017749309539795, Training Loss = 0.01364655327051878, Testing Loss = 0.019410801120102406\n",
      "Epoch 155, Weight = 1.9652944803237915, Bias = 0.2591550350189209, Training Loss = 0.013539496809244156, Testing Loss = 0.019258501939475536\n",
      "Epoch 156, Weight = 1.9654308557510376, Bias = 0.2581366002559662, Training Loss = 0.01343330554664135, Testing Loss = 0.019107398111373186\n",
      "Epoch 157, Weight = 1.9655667543411255, Bias = 0.2571221590042114, Training Loss = 0.013327935710549355, Testing Loss = 0.01895759953185916\n",
      "Epoch 158, Weight = 1.965701937675476, Bias = 0.2561117112636566, Training Loss = 0.013223367743194103, Testing Loss = 0.01880868198350072\n",
      "Epoch 159, Weight = 1.9658368825912476, Bias = 0.25510525703430176, Training Loss = 0.013119709677994251, Testing Loss = 0.018661312758922577\n",
      "Epoch 160, Weight = 1.9659709930419922, Bias = 0.2541027367115021, Training Loss = 0.013016700744628906, Testing Loss = 0.01851481292396784\n",
      "Epoch 161, Weight = 1.9661047458648682, Bias = 0.25310415029525757, Training Loss = 0.012914631515741348, Testing Loss = 0.018369659315794706\n",
      "Epoch 162, Weight = 1.966238021850586, Bias = 0.25210949778556824, Training Loss = 0.012813381850719452, Testing Loss = 0.01822558930143714\n",
      "Epoch 163, Weight = 1.966370701789856, Bias = 0.2511187493801117, Training Loss = 0.012712819501757622, Testing Loss = 0.01808266621083021\n",
      "Epoch 164, Weight = 1.9665027856826782, Bias = 0.25013187527656555, Training Loss = 0.012613068334758282, Testing Loss = 0.01794077316299081\n",
      "Epoch 165, Weight = 1.9666345119476318, Bias = 0.2491489052772522, Training Loss = 0.012514169327914715, Testing Loss = 0.017800054512917995\n",
      "Epoch 166, Weight = 1.9667655229568481, Bias = 0.24816977977752686, Training Loss = 0.01241596695035696, Testing Loss = 0.017660314217209816\n",
      "Epoch 167, Weight = 1.9668961763381958, Bias = 0.24719452857971191, Training Loss = 0.012318619526922703, Testing Loss = 0.017521915957331657\n",
      "Epoch 168, Weight = 1.9670262336730957, Bias = 0.2462230920791626, Training Loss = 0.012221958488225937, Testing Loss = 0.017384381499141455\n",
      "Epoch 169, Weight = 1.9671558141708374, Bias = 0.2452554851770401, Training Loss = 0.012126101180911064, Testing Loss = 0.017248026095330715\n",
      "Epoch 170, Weight = 1.9672847986221313, Bias = 0.24429166316986084, Training Loss = 0.012030948884785175, Testing Loss = 0.01711266301572323\n",
      "Epoch 171, Weight = 1.9674135446548462, Bias = 0.2433316558599472, Training Loss = 0.0119366105645895, Testing Loss = 0.016978505067527294\n",
      "Epoch 172, Weight = 1.9675415754318237, Bias = 0.24237538874149323, Training Loss = 0.01184296328574419, Testing Loss = 0.016845365520566702\n",
      "Epoch 173, Weight = 1.967669129371643, Bias = 0.2414228916168213, Training Loss = 0.011750055477023125, Testing Loss = 0.016713200602680445\n",
      "Epoch 174, Weight = 1.9677962064743042, Bias = 0.240474134683609, Training Loss = 0.011657905764877796, Testing Loss = 0.016582113690674305\n",
      "Epoch 175, Weight = 1.9679228067398071, Bias = 0.23952911794185638, Training Loss = 0.011566427536308765, Testing Loss = 0.016452095471322536\n",
      "Epoch 176, Weight = 1.9680488109588623, Bias = 0.23858781158924103, Training Loss = 0.011475706472992897, Testing Loss = 0.016322899609804153\n",
      "Epoch 177, Weight = 1.9681743383407593, Bias = 0.23765020072460175, Training Loss = 0.011385675519704819, Testing Loss = 0.016194934956729412\n",
      "Epoch 178, Weight = 1.968299388885498, Bias = 0.23671627044677734, Training Loss = 0.011296384036540985, Testing Loss = 0.016067849472165108\n",
      "Epoch 179, Weight = 1.9684239625930786, Bias = 0.23578600585460663, Training Loss = 0.011207733303308487, Testing Loss = 0.015941808931529522\n",
      "Epoch 180, Weight = 1.9685479402542114, Bias = 0.2348593920469284, Training Loss = 0.011119861155748367, Testing Loss = 0.015816636849194765\n",
      "Epoch 181, Weight = 1.9686715602874756, Bias = 0.23393644392490387, Training Loss = 0.01103261299431324, Testing Loss = 0.015692535787820816\n",
      "Epoch 182, Weight = 1.968794822692871, Bias = 0.23301713168621063, Training Loss = 0.010946081951260567, Testing Loss = 0.015569595620036125\n",
      "Epoch 183, Weight = 1.9689173698425293, Bias = 0.2321014106273651, Training Loss = 0.010860218666493893, Testing Loss = 0.015447440091520548\n",
      "Epoch 184, Weight = 1.9690395593643188, Bias = 0.2311892956495285, Training Loss = 0.010775027796626091, Testing Loss = 0.015326299704611301\n",
      "Epoch 185, Weight = 1.9691612720489502, Bias = 0.23028075695037842, Training Loss = 0.010690541937947273, Testing Loss = 0.015206169337034225\n",
      "Epoch 186, Weight = 1.9692825078964233, Bias = 0.22937579452991486, Training Loss = 0.010606693103909492, Testing Loss = 0.015086809173226357\n",
      "Epoch 187, Weight = 1.9694031476974487, Bias = 0.22847437858581543, Training Loss = 0.010523437522351742, Testing Loss = 0.014968382194638252\n",
      "Epoch 188, Weight = 1.9695234298706055, Bias = 0.22757652401924133, Training Loss = 0.010440937243402004, Testing Loss = 0.014851076994091272\n",
      "Epoch 189, Weight = 1.9696431159973145, Bias = 0.2266821712255478, Training Loss = 0.010358977131545544, Testing Loss = 0.014734464231878519\n",
      "Epoch 190, Weight = 1.9697624444961548, Bias = 0.22579136490821838, Training Loss = 0.010277741588652134, Testing Loss = 0.014618997927755117\n",
      "Epoch 191, Weight = 1.969881296157837, Bias = 0.22490404546260834, Training Loss = 0.010197107680141926, Testing Loss = 0.01450434047728777\n",
      "Epoch 192, Weight = 1.9699996709823608, Bias = 0.22402021288871765, Training Loss = 0.010117188096046448, Testing Loss = 0.014390525408089161\n",
      "Epoch 193, Weight = 1.9701175689697266, Bias = 0.22313985228538513, Training Loss = 0.010037770494818687, Testing Loss = 0.014277639798820019\n",
      "Epoch 194, Weight = 1.970234990119934, Bias = 0.22226294875144958, Training Loss = 0.009959008544683456, Testing Loss = 0.014165648724883795\n",
      "Epoch 195, Weight = 1.9703519344329834, Bias = 0.22138948738574982, Training Loss = 0.009880929253995419, Testing Loss = 0.01405448466539383\n",
      "Epoch 196, Weight = 1.9704684019088745, Bias = 0.22051946818828583, Training Loss = 0.009803395718336105, Testing Loss = 0.013944232370704412\n",
      "Epoch 197, Weight = 1.970584511756897, Bias = 0.21965287625789642, Training Loss = 0.009726492688059807, Testing Loss = 0.013834860641509295\n",
      "Epoch 198, Weight = 1.9707001447677612, Bias = 0.21878968179225922, Training Loss = 0.00965025369077921, Testing Loss = 0.013726361561566591\n",
      "Epoch 199, Weight = 1.9708151817321777, Bias = 0.217929869890213, Training Loss = 0.0095745287835598, Testing Loss = 0.013618636410683393\n",
      "Epoch 200, Weight = 1.9709298610687256, Bias = 0.2170734405517578, Training Loss = 0.009499398991465569, Testing Loss = 0.013511774130165577\n",
      "Epoch 201, Weight = 1.9710441827774048, Bias = 0.21622039377689362, Training Loss = 0.009424888528883457, Testing Loss = 0.013405894860625267\n",
      "Epoch 202, Weight = 1.9711579084396362, Bias = 0.21537068486213684, Training Loss = 0.009350993670523167, Testing Loss = 0.013300650753080845\n",
      "Epoch 203, Weight = 1.971271276473999, Bias = 0.21452432870864868, Training Loss = 0.009277663193643093, Testing Loss = 0.013196316547691822\n",
      "Epoch 204, Weight = 1.9713841676712036, Bias = 0.21368128061294556, Training Loss = 0.009204800240695477, Testing Loss = 0.013092887587845325\n",
      "Epoch 205, Weight = 1.97149658203125, Bias = 0.21284154057502747, Training Loss = 0.009132609702646732, Testing Loss = 0.012990142684429884\n",
      "Epoch 206, Weight = 1.9716086387634277, Bias = 0.2120051234960556, Training Loss = 0.009061027318239212, Testing Loss = 0.012888197787106037\n",
      "Epoch 207, Weight = 1.9717202186584473, Bias = 0.2111719846725464, Training Loss = 0.00898988451808691, Testing Loss = 0.012787176761776209\n",
      "Epoch 208, Weight = 1.9718314409255981, Bias = 0.21034212410449982, Training Loss = 0.008919433690607548, Testing Loss = 0.01268688589334488\n",
      "Epoch 209, Weight = 1.9719420671463013, Bias = 0.2095154970884323, Training Loss = 0.008849438279867172, Testing Loss = 0.01258732145652175\n",
      "Epoch 210, Weight = 1.9720523357391357, Bias = 0.20869213342666626, Training Loss = 0.0087800407782197, Testing Loss = 0.012488605454564095\n",
      "Epoch 211, Weight = 1.972162127494812, Bias = 0.20787200331687927, Training Loss = 0.008711143396794796, Testing Loss = 0.012390573974698782\n",
      "Epoch 212, Weight = 1.9722715616226196, Bias = 0.20705510675907135, Training Loss = 0.008642838336527348, Testing Loss = 0.012293499894440174\n",
      "Epoch 213, Weight = 1.972380518913269, Bias = 0.2062414139509201, Training Loss = 0.008575009182095528, Testing Loss = 0.012196983676403761\n",
      "Epoch 214, Weight = 1.9724891185760498, Bias = 0.20543092489242554, Training Loss = 0.008507763035595417, Testing Loss = 0.012101355474442244\n",
      "Epoch 215, Weight = 1.9725972414016724, Bias = 0.20462360978126526, Training Loss = 0.008441024459898472, Testing Loss = 0.01200648583471775\n",
      "Epoch 216, Weight = 1.9727048873901367, Bias = 0.20381946861743927, Training Loss = 0.00837476272135973, Testing Loss = 0.011912195943295956\n",
      "Epoch 217, Weight = 1.9728121757507324, Bias = 0.20301848649978638, Training Loss = 0.00830909889191389, Testing Loss = 0.011818805243819952\n",
      "Epoch 218, Weight = 1.97291898727417, Bias = 0.20222066342830658, Training Loss = 0.0082439249381423, Testing Loss = 0.0117260767146945\n",
      "Epoch 219, Weight = 1.9730253219604492, Bias = 0.2014259696006775, Training Loss = 0.00817924551665783, Testing Loss = 0.011634000111371279\n",
      "Epoch 220, Weight = 1.9731314182281494, Bias = 0.2006344199180603, Training Loss = 0.008115105330944061, Testing Loss = 0.011542839463800192\n",
      "Epoch 221, Weight = 1.9732370376586914, Bias = 0.19984596967697144, Training Loss = 0.00805147085338831, Testing Loss = 0.0114523284137249\n",
      "Epoch 222, Weight = 1.9733421802520752, Bias = 0.1990606039762497, Training Loss = 0.007988302037119865, Testing Loss = 0.011362457647919655\n",
      "Epoch 223, Weight = 1.9734469652175903, Bias = 0.19827833771705627, Training Loss = 0.007925635203719139, Testing Loss = 0.011273343116044998\n",
      "Epoch 224, Weight = 1.9735512733459473, Bias = 0.1974991261959076, Training Loss = 0.007863454520702362, Testing Loss = 0.01118492241948843\n",
      "Epoch 225, Weight = 1.973655343055725, Bias = 0.19672299921512604, Training Loss = 0.007801823318004608, Testing Loss = 0.011097304988652468\n",
      "Epoch 226, Weight = 1.9737586975097656, Bias = 0.19594989717006683, Training Loss = 0.007740577682852745, Testing Loss = 0.011010057758539915\n",
      "Epoch 227, Weight = 1.9738619327545166, Bias = 0.19517986476421356, Training Loss = 0.007679864764213562, Testing Loss = 0.010923834051936865\n",
      "Epoch 228, Weight = 1.9739646911621094, Bias = 0.19441284239292145, Training Loss = 0.007619664538651705, Testing Loss = 0.010838146321475506\n",
      "Epoch 229, Weight = 1.974066972732544, Bias = 0.1936488151550293, Training Loss = 0.007559875957667828, Testing Loss = 0.010753072332590818\n",
      "Epoch 230, Weight = 1.9741687774658203, Bias = 0.1928877979516983, Training Loss = 0.007500547915697098, Testing Loss = 0.010668699163943529\n",
      "Epoch 231, Weight = 1.9742703437805176, Bias = 0.19212977588176727, Training Loss = 0.007441711612045765, Testing Loss = 0.010585018433630466\n",
      "Epoch 232, Weight = 1.9743715524673462, Bias = 0.1913747489452362, Training Loss = 0.007383374497294426, Testing Loss = 0.010502024553716183\n",
      "Epoch 233, Weight = 1.9744722843170166, Bias = 0.19062267243862152, Training Loss = 0.007325435057282448, Testing Loss = 0.010419689118862152\n",
      "Epoch 234, Weight = 1.9745725393295288, Bias = 0.18987354636192322, Training Loss = 0.0072679705917835236, Testing Loss = 0.010337870102375746\n",
      "Epoch 235, Weight = 1.9746724367141724, Bias = 0.1891273707151413, Training Loss = 0.007210969924926758, Testing Loss = 0.010256811045110226\n",
      "Epoch 236, Weight = 1.9747719764709473, Bias = 0.18838413059711456, Training Loss = 0.007154364138841629, Testing Loss = 0.010176315438002348\n",
      "Epoch 237, Weight = 1.974871039390564, Bias = 0.18764381110668182, Training Loss = 0.0070982459001243114, Testing Loss = 0.010096434038132429\n",
      "Epoch 238, Weight = 1.9749698638916016, Bias = 0.18690641224384308, Training Loss = 0.007042599376291037, Testing Loss = 0.010017329594120383\n",
      "Epoch 239, Weight = 1.975068211555481, Bias = 0.18617188930511475, Training Loss = 0.006987333297729492, Testing Loss = 0.009938748320564628\n",
      "Epoch 240, Weight = 1.9751662015914917, Bias = 0.18544025719165802, Training Loss = 0.006932497955858707, Testing Loss = 0.00986074609681964\n",
      "Epoch 241, Weight = 1.9752638339996338, Bias = 0.1847115159034729, Training Loss = 0.006878156680613756, Testing Loss = 0.00978344981558621\n",
      "Epoch 242, Weight = 1.9753609895706177, Bias = 0.1839856207370758, Training Loss = 0.006824200507253408, Testing Loss = 0.00970664364285767\n",
      "Epoch 243, Weight = 1.975457787513733, Bias = 0.18326258659362793, Training Loss = 0.006770669016987085, Testing Loss = 0.00963051151484251\n",
      "Epoch 244, Weight = 1.975554347038269, Bias = 0.18254239857196808, Training Loss = 0.006717589683830738, Testing Loss = 0.009554997319355607\n",
      "Epoch 245, Weight = 1.9756503105163574, Bias = 0.18182502686977386, Training Loss = 0.006664866115897894, Testing Loss = 0.009479987667873502\n",
      "Epoch 246, Weight = 1.9757460355758667, Bias = 0.18111048638820648, Training Loss = 0.006612540688365698, Testing Loss = 0.009405669290572405\n",
      "Epoch 247, Weight = 1.9758414030075073, Bias = 0.18039876222610474, Training Loss = 0.00656072236597538, Testing Loss = 0.009331900626420975\n",
      "Epoch 248, Weight = 1.9759362936019897, Bias = 0.17968982458114624, Training Loss = 0.006509254686534405, Testing Loss = 0.009258683770895004\n",
      "Epoch 249, Weight = 1.976030945777893, Bias = 0.178983673453331, Training Loss = 0.0064581758342683315, Testing Loss = 0.009186090203002095\n",
      "Epoch 250, Weight = 1.9761250019073486, Bias = 0.1782802939414978, Training Loss = 0.006407511420547962, Testing Loss = 0.009113962762057781\n",
      "Epoch 251, Weight = 1.9762189388275146, Bias = 0.17757968604564667, Training Loss = 0.006357268895953894, Testing Loss = 0.009042558493092656\n",
      "Epoch 252, Weight = 1.976312279701233, Bias = 0.1768818199634552, Training Loss = 0.006307387258857489, Testing Loss = 0.008971586357802153\n",
      "Epoch 253, Weight = 1.976405382156372, Bias = 0.1761867105960846, Training Loss = 0.006257935892790556, Testing Loss = 0.008901172550395131\n",
      "Epoch 254, Weight = 1.9764981269836426, Bias = 0.17549432814121246, Training Loss = 0.00620880676433444, Testing Loss = 0.008831341983750463\n",
      "Epoch 255, Weight = 1.9765905141830444, Bias = 0.1748046725988388, Training Loss = 0.006160115823149681, Testing Loss = 0.008762063225731254\n",
      "Epoch 256, Weight = 1.9766825437545776, Bias = 0.17411771416664124, Training Loss = 0.006111794151365757, Testing Loss = 0.0086933602578938\n",
      "Epoch 257, Weight = 1.9767740964889526, Bias = 0.17343345284461975, Training Loss = 0.0060638743452727795, Testing Loss = 0.00862515321932733\n",
      "Epoch 258, Weight = 1.9768654108047485, Bias = 0.17275190353393555, Training Loss = 0.0060163079760968685, Testing Loss = 0.008557537337765098\n",
      "Epoch 259, Weight = 1.9769563674926758, Bias = 0.17207302153110504, Training Loss = 0.005969114135950804, Testing Loss = 0.008490438340231776\n",
      "Epoch 260, Weight = 1.9770468473434448, Bias = 0.17139679193496704, Training Loss = 0.005922288168221712, Testing Loss = 0.008423750288784504\n",
      "Epoch 261, Weight = 1.9771370887756348, Bias = 0.17072324454784393, Training Loss = 0.005875864066183567, Testing Loss = 0.008357719983905554\n",
      "Epoch 262, Weight = 1.977226972579956, Bias = 0.17005233466625214, Training Loss = 0.005829750560224056, Testing Loss = 0.008292196551337838\n",
      "Epoch 263, Weight = 1.9773164987564087, Bias = 0.16938404738903046, Training Loss = 0.005784028675407171, Testing Loss = 0.008227199548855424\n",
      "Epoch 264, Weight = 1.9774055480957031, Bias = 0.1687183827161789, Training Loss = 0.005738640204071999, Testing Loss = 0.008162554819136858\n",
      "Epoch 265, Weight = 1.9774943590164185, Bias = 0.16805535554885864, Training Loss = 0.005693614017218351, Testing Loss = 0.00809855293482542\n",
      "Epoch 266, Weight = 1.9775828123092651, Bias = 0.16739492118358612, Training Loss = 0.005648974794894457, Testing Loss = 0.00803504721261561\n",
      "Epoch 267, Weight = 1.9776710271835327, Bias = 0.16673709452152252, Training Loss = 0.005604654550552368, Testing Loss = 0.007972055580466986\n",
      "Epoch 268, Weight = 1.9777586460113525, Bias = 0.16608183085918427, Training Loss = 0.005560702178627253, Testing Loss = 0.007909453939646482\n",
      "Epoch 269, Weight = 1.9778460264205933, Bias = 0.16542915999889374, Training Loss = 0.005517052952200174, Testing Loss = 0.007847413187846541\n",
      "Epoch 270, Weight = 1.9779330492019653, Bias = 0.16477905213832855, Training Loss = 0.005473780445754528, Testing Loss = 0.00778585160151124\n",
      "Epoch 271, Weight = 1.9780198335647583, Bias = 0.1641315072774887, Training Loss = 0.005430819932371378, Testing Loss = 0.007724818075075746\n",
      "Epoch 272, Weight = 1.978106141090393, Bias = 0.16348649561405182, Training Loss = 0.005388232413679361, Testing Loss = 0.007664191070944071\n",
      "Epoch 273, Weight = 1.9781922101974487, Bias = 0.16284403204917908, Training Loss = 0.005345989018678665, Testing Loss = 0.007604060461744666\n",
      "Epoch 274, Weight = 1.9782780408859253, Bias = 0.1622041016817093, Training Loss = 0.0053040445782244205, Testing Loss = 0.007544495165348053\n",
      "Epoch 275, Weight = 1.978363275527954, Bias = 0.16156665980815887, Training Loss = 0.005262418650090694, Testing Loss = 0.007485256530344486\n",
      "Epoch 276, Weight = 1.9784483909606934, Bias = 0.16093173623085022, Training Loss = 0.005221194587647915, Testing Loss = 0.007426531286910176\n",
      "Epoch 277, Weight = 1.9785330295562744, Bias = 0.16029928624629974, Training Loss = 0.0051801688969135284, Testing Loss = 0.007368291495367885\n",
      "Epoch 278, Weight = 1.9786174297332764, Bias = 0.15966933965682983, Training Loss = 0.005139578133821487, Testing Loss = 0.007310442626476288\n",
      "Epoch 279, Weight = 1.9787014722824097, Bias = 0.1590418666601181, Training Loss = 0.005099232774227858, Testing Loss = 0.0072531444020569324\n",
      "Epoch 280, Weight = 1.9787851572036743, Bias = 0.15841685235500336, Training Loss = 0.005059223622083664, Testing Loss = 0.007196276914328337\n",
      "Epoch 281, Weight = 1.9788684844970703, Bias = 0.1577942967414856, Training Loss = 0.005019570235162973, Testing Loss = 0.007139768684282899\n",
      "Epoch 282, Weight = 1.9789515733718872, Bias = 0.15717418491840363, Training Loss = 0.004980174358934164, Testing Loss = 0.007083826465532184\n",
      "Epoch 283, Weight = 1.979034185409546, Bias = 0.15655650198459625, Training Loss = 0.004941109102219343, Testing Loss = 0.007028123829513788\n",
      "Epoch 284, Weight = 1.979116678237915, Bias = 0.15594126284122467, Training Loss = 0.004902342800050974, Testing Loss = 0.006973115028813481\n",
      "Epoch 285, Weight = 1.979198694229126, Bias = 0.1553284376859665, Training Loss = 0.004863924812525511, Testing Loss = 0.006918391911312938\n",
      "Epoch 286, Weight = 1.9792804718017578, Bias = 0.15471802651882172, Training Loss = 0.004825763404369354, Testing Loss = 0.006864128867164254\n",
      "Epoch 287, Weight = 1.979361891746521, Bias = 0.15410999953746796, Training Loss = 0.004787894897162914, Testing Loss = 0.006810279795899987\n",
      "Epoch 288, Weight = 1.9794429540634155, Bias = 0.1535043716430664, Training Loss = 0.004750351887196302, Testing Loss = 0.006756773684173822\n",
      "Epoch 289, Weight = 1.979523777961731, Bias = 0.15290112793445587, Training Loss = 0.004713104572147131, Testing Loss = 0.0067038568668067455\n",
      "Epoch 290, Weight = 1.9796042442321777, Bias = 0.15230025351047516, Training Loss = 0.004676101729273796, Testing Loss = 0.006651234580203891\n",
      "Epoch 291, Weight = 1.9796843528747559, Bias = 0.15170173346996307, Training Loss = 0.004639425780624151, Testing Loss = 0.0065990842413157225\n",
      "Epoch 292, Weight = 1.9797642230987549, Bias = 0.15110556781291962, Training Loss = 0.0046030497178435326, Testing Loss = 0.0065473346039652824\n",
      "Epoch 293, Weight = 1.9798437356948853, Bias = 0.1505117416381836, Training Loss = 0.004566929303109646, Testing Loss = 0.00649598496966064\n",
      "Epoch 294, Weight = 1.9799230098724365, Bias = 0.1499202698469162, Training Loss = 0.004531114362180233, Testing Loss = 0.006445031613111496\n",
      "Epoch 295, Weight = 1.9800019264221191, Bias = 0.14933110773563385, Training Loss = 0.004495576955378056, Testing Loss = 0.0063944729045033455\n",
      "Epoch 296, Weight = 1.980080485343933, Bias = 0.14874425530433655, Training Loss = 0.004460289608687162, Testing Loss = 0.006344263907521963\n",
      "Epoch 297, Weight = 1.9801586866378784, Bias = 0.1481597125530243, Training Loss = 0.004425313789397478, Testing Loss = 0.006294445600360632\n",
      "Epoch 298, Weight = 1.9802367687225342, Bias = 0.14757747948169708, Training Loss = 0.004390616901218891, Testing Loss = 0.006245122291147709\n",
      "Epoch 299, Weight = 1.9803143739700317, Bias = 0.14699752628803253, Training Loss = 0.0043561519123613834, Testing Loss = 0.006196184083819389\n",
      "Epoch 300, Weight = 1.9803917407989502, Bias = 0.14641985297203064, Training Loss = 0.004321984481066465, Testing Loss = 0.006147563923150301\n",
      "Epoch 301, Weight = 1.9804688692092896, Bias = 0.1458444446325302, Training Loss = 0.004288087598979473, Testing Loss = 0.006099347257986665\n",
      "Epoch 302, Weight = 1.9805455207824707, Bias = 0.14527128636837006, Training Loss = 0.004254448227584362, Testing Loss = 0.006051467964425683\n",
      "Epoch 303, Weight = 1.9806220531463623, Bias = 0.14470040798187256, Training Loss = 0.004221085924655199, Testing Loss = 0.006004006136208773\n",
      "Epoch 304, Weight = 1.9806981086730957, Bias = 0.14413174986839294, Training Loss = 0.004187943413853645, Testing Loss = 0.005956877721473575\n",
      "Epoch 305, Weight = 1.9807740449905396, Bias = 0.1435653418302536, Training Loss = 0.004155099391937256, Testing Loss = 0.005910225445404649\n",
      "Epoch 306, Weight = 1.9808495044708252, Bias = 0.14300113916397095, Training Loss = 0.004122491925954819, Testing Loss = 0.005863838596269488\n",
      "Epoch 307, Weight = 1.9809247255325317, Bias = 0.14243917167186737, Training Loss = 0.004090178292244673, Testing Loss = 0.005817819153890014\n",
      "Epoch 308, Weight = 1.9809997081756592, Bias = 0.14187942445278168, Training Loss = 0.004058089107275009, Testing Loss = 0.0057721249759197235\n",
      "Epoch 309, Weight = 1.9810744524002075, Bias = 0.14132186770439148, Training Loss = 0.004026245325803757, Testing Loss = 0.005726897157728672\n",
      "Epoch 310, Weight = 1.9811488389968872, Bias = 0.14076648652553558, Training Loss = 0.00399469630792737, Testing Loss = 0.005682030227035284\n",
      "Epoch 311, Weight = 1.9812228679656982, Bias = 0.14021329581737518, Training Loss = 0.003963341936469078, Testing Loss = 0.005637379828840494\n",
      "Epoch 312, Weight = 1.9812967777252197, Bias = 0.13966229557991028, Training Loss = 0.003932258579879999, Testing Loss = 0.005593290086835623\n",
      "Epoch 313, Weight = 1.981370210647583, Bias = 0.1391134411096573, Training Loss = 0.003901435062289238, Testing Loss = 0.0055493516847491264\n",
      "Epoch 314, Weight = 1.9814434051513672, Bias = 0.1385667473077774, Training Loss = 0.0038707901258021593, Testing Loss = 0.00550582748837769\n",
      "Epoch 315, Weight = 1.9815163612365723, Bias = 0.13802219927310944, Training Loss = 0.0038404492661356926, Testing Loss = 0.005462654400616884\n",
      "Epoch 316, Weight = 1.9815890789031982, Bias = 0.13747979700565338, Training Loss = 0.003810351248830557, Testing Loss = 0.005419790279120207\n",
      "Epoch 317, Weight = 1.981661319732666, Bias = 0.13693951070308685, Training Loss = 0.0037804266903549433, Testing Loss = 0.005377212073653936\n",
      "Epoch 318, Weight = 1.9817334413528442, Bias = 0.13640137016773224, Training Loss = 0.0037507680244743824, Testing Loss = 0.005335099762305617\n",
      "Epoch 319, Weight = 1.9818050861358643, Bias = 0.13586531579494476, Training Loss = 0.0037213258910924196, Testing Loss = 0.00529317045584321\n",
      "Epoch 320, Weight = 1.9818766117095947, Bias = 0.135331392288208, Training Loss = 0.003692139871418476, Testing Loss = 0.005251642316579819\n",
      "Epoch 321, Weight = 1.981947898864746, Bias = 0.13479956984519958, Training Loss = 0.0036631959956139326, Testing Loss = 0.005210512317717075\n",
      "Epoch 322, Weight = 1.9820188283920288, Bias = 0.1342698186635971, Training Loss = 0.003634452586993575, Testing Loss = 0.005169620621018112\n",
      "Epoch 323, Weight = 1.9820895195007324, Bias = 0.13374216854572296, Training Loss = 0.0036059583071619272, Testing Loss = 0.0051291019190102816\n",
      "Epoch 324, Weight = 1.9821598529815674, Bias = 0.13321657478809357, Training Loss = 0.0035776779986917973, Testing Loss = 0.0050888394471257925\n",
      "Epoch 325, Weight = 1.9822299480438232, Bias = 0.13269305229187012, Training Loss = 0.003549602348357439, Testing Loss = 0.005048908176831901\n",
      "Epoch 326, Weight = 1.9822998046875, Bias = 0.1321716010570526, Training Loss = 0.0035217702388763428, Testing Loss = 0.005009305663406849\n",
      "Epoch 327, Weight = 1.9823694229125977, Bias = 0.13165219128131866, Training Loss = 0.003494136966764927, Testing Loss = 0.004970030160620809\n",
      "Epoch 328, Weight = 1.9824386835098267, Bias = 0.13113482296466827, Training Loss = 0.0034667178988456726, Testing Loss = 0.004931041854433715\n",
      "Epoch 329, Weight = 1.9825077056884766, Bias = 0.13061949610710144, Training Loss = 0.003439555410295725, Testing Loss = 0.004892339929938316\n",
      "Epoch 330, Weight = 1.9825764894485474, Bias = 0.13010618090629578, Training Loss = 0.0034125549718737602, Testing Loss = 0.00485401670448482\n",
      "Epoch 331, Weight = 1.9826449155807495, Bias = 0.12959487736225128, Training Loss = 0.003385774092748761, Testing Loss = 0.00481591816060245\n",
      "Epoch 332, Weight = 1.9827131032943726, Bias = 0.12908560037612915, Training Loss = 0.003359238151460886, Testing Loss = 0.004778137197718024\n",
      "Epoch 333, Weight = 1.9827810525894165, Bias = 0.128578320145607, Training Loss = 0.0033328807912766933, Testing Loss = 0.004740672302432358\n",
      "Epoch 334, Weight = 1.9828487634658813, Bias = 0.12807303667068481, Training Loss = 0.0033067327458411455, Testing Loss = 0.004703521146439016\n",
      "Epoch 335, Weight = 1.9829161167144775, Bias = 0.12756973505020142, Training Loss = 0.0032807989045977592, Testing Loss = 0.0046666087582707405\n",
      "Epoch 336, Weight = 1.9829832315444946, Bias = 0.1270684003829956, Training Loss = 0.0032550785690546036, Testing Loss = 0.004629950737580657\n",
      "Epoch 337, Weight = 1.9830501079559326, Bias = 0.12656904757022858, Training Loss = 0.0032295375131070614, Testing Loss = 0.004593621473759413\n",
      "Epoch 338, Weight = 1.9831167459487915, Bias = 0.12607164680957794, Training Loss = 0.003204178297892213, Testing Loss = 0.0045575989643111825\n",
      "Epoch 339, Weight = 1.9831830263137817, Bias = 0.1255761981010437, Training Loss = 0.0031790549401193857, Testing Loss = 0.004521845723502338\n",
      "Epoch 340, Weight = 1.9832491874694824, Bias = 0.12508270144462585, Training Loss = 0.003154111560434103, Testing Loss = 0.004486395628191531\n",
      "Epoch 341, Weight = 1.9833149909973145, Bias = 0.12459114193916321, Training Loss = 0.0031293798238039017, Testing Loss = 0.004451191518455744\n",
      "Epoch 342, Weight = 1.9833805561065674, Bias = 0.12410151958465576, Training Loss = 0.003104826435446739, Testing Loss = 0.004416306735947728\n",
      "Epoch 343, Weight = 1.9834458827972412, Bias = 0.12361381947994232, Training Loss = 0.0030804751440882683, Testing Loss = 0.004381594713777304\n",
      "Epoch 344, Weight = 1.983510971069336, Bias = 0.12312804162502289, Training Loss = 0.0030563040636479855, Testing Loss = 0.004347268957644701\n",
      "Epoch 345, Weight = 1.983575701713562, Bias = 0.12264416366815567, Training Loss = 0.0030323148239403963, Testing Loss = 0.004313113517127931\n",
      "Epoch 346, Weight = 1.9836403131484985, Bias = 0.12216220051050186, Training Loss = 0.00300855515524745, Testing Loss = 0.004279374843463302\n",
      "Epoch 347, Weight = 1.983704686164856, Bias = 0.12168212980031967, Training Loss = 0.002984954509884119, Testing Loss = 0.0042458034586161375\n",
      "Epoch 348, Weight = 1.9837685823440552, Bias = 0.12120392918586731, Training Loss = 0.002961542923003435, Testing Loss = 0.0042124525643885136\n",
      "Epoch 349, Weight = 1.9838322401046753, Bias = 0.12072760611772537, Training Loss = 0.0029383040964603424, Testing Loss = 0.004179355571977794\n",
      "Epoch 350, Weight = 1.9838958978652954, Bias = 0.12025319039821625, Training Loss = 0.002915262710303068, Testing Loss = 0.004146613646298647\n",
      "Epoch 351, Weight = 1.9839591979980469, Bias = 0.11978062242269516, Training Loss = 0.0028924131765961647, Testing Loss = 0.004114088020287454\n",
      "Epoch 352, Weight = 1.9840222597122192, Bias = 0.11930990219116211, Training Loss = 0.002869680989533663, Testing Loss = 0.004081845283508301\n",
      "Epoch 353, Weight = 1.984084963798523, Bias = 0.1188410297036171, Training Loss = 0.002847169293090701, Testing Loss = 0.004049763083457947\n",
      "Epoch 354, Weight = 1.984147548675537, Bias = 0.11837401986122131, Training Loss = 0.002824861090630293, Testing Loss = 0.00401801394764334\n",
      "Epoch 355, Weight = 1.9842098951339722, Bias = 0.11790883541107178, Training Loss = 0.002802687929943204, Testing Loss = 0.0039865425787866116\n",
      "Epoch 356, Weight = 1.9842720031738281, Bias = 0.11744548380374908, Training Loss = 0.0027807115111500025, Testing Loss = 0.0039553140522912145\n",
      "Epoch 357, Weight = 1.9843337535858154, Bias = 0.11698393523693085, Training Loss = 0.0027589143719524145, Testing Loss = 0.0039242415223270655\n",
      "Epoch 358, Weight = 1.9843952655792236, Bias = 0.11652420461177826, Training Loss = 0.002737270202487707, Testing Loss = 0.0038934247568249702\n",
      "Epoch 359, Weight = 1.9844566583633423, Bias = 0.11606629192829132, Training Loss = 0.0027157894801348448, Testing Loss = 0.0038629499031230807\n",
      "Epoch 360, Weight = 1.9845178127288818, Bias = 0.11561017483472824, Training Loss = 0.0026944889687001705, Testing Loss = 0.0038326275534927845\n",
      "Epoch 361, Weight = 1.9845786094665527, Bias = 0.11515583097934723, Training Loss = 0.0026733381673693657, Testing Loss = 0.0038025742396712303\n",
      "Epoch 362, Weight = 1.984639048576355, Bias = 0.11470327526330948, Training Loss = 0.0026523678097873926, Testing Loss = 0.0037726720329374075\n",
      "Epoch 363, Weight = 1.9846994876861572, Bias = 0.11425252258777618, Training Loss = 0.002631561364978552, Testing Loss = 0.0037431013770401478\n",
      "Epoch 364, Weight = 1.9847596883773804, Bias = 0.11380354315042496, Training Loss = 0.0026109381578862667, Testing Loss = 0.003713747952133417\n",
      "Epoch 365, Weight = 1.9848195314407349, Bias = 0.11335630714893341, Training Loss = 0.0025904488284140825, Testing Loss = 0.0036846069851890206\n",
      "Epoch 366, Weight = 1.9848791360855103, Bias = 0.11291082948446274, Training Loss = 0.0025701350532472134, Testing Loss = 0.0036556952400133014\n",
      "Epoch 367, Weight = 1.984938621520996, Bias = 0.11246711015701294, Training Loss = 0.002549971453845501, Testing Loss = 0.0036270433338359\n",
      "Epoch 368, Weight = 1.9849978685379028, Bias = 0.11202513426542282, Training Loss = 0.0025299615226686, Testing Loss = 0.00359861773904413\n",
      "Epoch 369, Weight = 1.985056757926941, Bias = 0.11158488690853119, Training Loss = 0.0025101301725953817, Testing Loss = 0.003570353495888412\n",
      "Epoch 370, Weight = 1.9851155281066895, Bias = 0.11114638298749924, Training Loss = 0.0024904138408601284, Testing Loss = 0.003542358987033367\n",
      "Epoch 371, Weight = 1.9851740598678589, Bias = 0.11070960015058517, Training Loss = 0.002470890525728464, Testing Loss = 0.0035146044101566076\n",
      "Epoch 372, Weight = 1.9852323532104492, Bias = 0.1102745309472084, Training Loss = 0.0024514992255717516, Testing Loss = 0.00348702201154083\n",
      "Epoch 373, Weight = 1.985290288925171, Bias = 0.10984115302562714, Training Loss = 0.0024322576355189085, Testing Loss = 0.003459659405052662\n",
      "Epoch 374, Weight = 1.985348105430603, Bias = 0.10940949618816376, Training Loss = 0.0024132118560373783, Testing Loss = 0.0034325155429542065\n",
      "Epoch 375, Weight = 1.985405683517456, Bias = 0.10897953063249588, Training Loss = 0.0023942668922245502, Testing Loss = 0.0034055719152092934\n",
      "Epoch 376, Weight = 1.98546302318573, Bias = 0.1085512563586235, Training Loss = 0.0023754769936203957, Testing Loss = 0.0033788614673539996\n",
      "Epoch 377, Weight = 1.9855202436447144, Bias = 0.10812467336654663, Training Loss = 0.002356855198740959, Testing Loss = 0.003352379542775452\n",
      "Epoch 378, Weight = 1.98557710647583, Bias = 0.10769975930452347, Training Loss = 0.0023383789230138063, Testing Loss = 0.0033260801574215293\n",
      "Epoch 379, Weight = 1.9856337308883667, Bias = 0.10727651417255402, Training Loss = 0.002320024650543928, Testing Loss = 0.0032999624963849783\n",
      "Epoch 380, Weight = 1.9856902360916138, Bias = 0.10685493797063828, Training Loss = 0.0023018375504761934, Testing Loss = 0.0032741170143708587\n",
      "Epoch 381, Weight = 1.9857463836669922, Bias = 0.10643500089645386, Training Loss = 0.002283775946125388, Testing Loss = 0.003248373279348016\n",
      "Epoch 382, Weight = 1.985802412033081, Bias = 0.10601673275232315, Training Loss = 0.0022658405359834433, Testing Loss = 0.0032229156931862235\n",
      "Epoch 383, Weight = 1.9858582019805908, Bias = 0.10560011118650436, Training Loss = 0.002248090924695134, Testing Loss = 0.003197648678906262\n",
      "Epoch 384, Weight = 1.9859137535095215, Bias = 0.1051851212978363, Training Loss = 0.0022304453887045383, Testing Loss = 0.003172557451762259\n",
      "Epoch 385, Weight = 1.9859691858291626, Bias = 0.10477176308631897, Training Loss = 0.0022129544522613287, Testing Loss = 0.0031477012671530247\n",
      "Epoch 386, Weight = 1.986024260520935, Bias = 0.10436002910137177, Training Loss = 0.0021955855190753937, Testing Loss = 0.003122972557321191\n",
      "Epoch 387, Weight = 1.986079216003418, Bias = 0.10394991934299469, Training Loss = 0.002178353723138571, Testing Loss = 0.003098476445302367\n",
      "Epoch 388, Weight = 1.9861339330673218, Bias = 0.10354141145944595, Training Loss = 0.002161269308999181, Testing Loss = 0.003074197913520038\n",
      "Epoch 389, Weight = 1.9861884117126465, Bias = 0.10313450545072556, Training Loss = 0.002144317142665386, Testing Loss = 0.0030500576831400394\n",
      "Epoch 390, Weight = 1.986242651939392, Bias = 0.10272920876741409, Training Loss = 0.0021275016479194164, Testing Loss = 0.0030261327046900988\n",
      "Epoch 391, Weight = 1.9862967729568481, Bias = 0.10232550650835037, Training Loss = 0.002110800240188837, Testing Loss = 0.0030024347361177206\n",
      "Epoch 392, Weight = 1.986350655555725, Bias = 0.1019233837723732, Training Loss = 0.002094266237691045, Testing Loss = 0.0029788882238790393\n",
      "Epoch 393, Weight = 1.986404299736023, Bias = 0.10152284801006317, Training Loss = 0.002077836077660322, Testing Loss = 0.0029555083019658923\n",
      "Epoch 394, Weight = 1.9864578247070312, Bias = 0.1011238843202591, Training Loss = 0.0020615383982658386, Testing Loss = 0.002932351897470653\n",
      "Epoch 395, Weight = 1.9865108728408813, Bias = 0.10072647035121918, Training Loss = 0.0020453615579754114, Testing Loss = 0.00290931505151093\n",
      "Epoch 396, Weight = 1.9865639209747314, Bias = 0.10033063590526581, Training Loss = 0.0020293109118938446, Testing Loss = 0.002886499511078\n",
      "Epoch 397, Weight = 1.9866167306900024, Bias = 0.0999363511800766, Training Loss = 0.002013406017795205, Testing Loss = 0.0028638464864343405\n",
      "Epoch 398, Weight = 1.9866693019866943, Bias = 0.09954361617565155, Training Loss = 0.0019976196344941854, Testing Loss = 0.0028413552790880203\n",
      "Epoch 399, Weight = 1.9867216348648071, Bias = 0.09915242344141006, Training Loss = 0.0019819182343780994, Testing Loss = 0.0028190657030791044\n",
      "Epoch 400, Weight = 1.9867738485336304, Bias = 0.09876278042793274, Training Loss = 0.001966403564438224, Testing Loss = 0.002796979737468064\n",
      "Epoch 401, Weight = 1.9868258237838745, Bias = 0.09837466478347778, Training Loss = 0.0019509692210704088, Testing Loss = 0.002775036613456905\n",
      "Epoch 402, Weight = 1.986877679824829, Bias = 0.0979880765080452, Training Loss = 0.0019356574630364776, Testing Loss = 0.00275330722797662\n",
      "Epoch 403, Weight = 1.986929178237915, Bias = 0.09760299324989319, Training Loss = 0.0019204879645258188, Testing Loss = 0.0027316631749272346\n",
      "Epoch 404, Weight = 1.9869805574417114, Bias = 0.09721943736076355, Training Loss = 0.0019054206786677241, Testing Loss = 0.0027102308813482523\n",
      "Epoch 405, Weight = 1.9870316982269287, Bias = 0.09683737903833389, Training Loss = 0.0018904578173533082, Testing Loss = 0.0026889535365626216\n",
      "Epoch 406, Weight = 1.9870827198028564, Bias = 0.09645682573318481, Training Loss = 0.0018756224308162928, Testing Loss = 0.0026679126312956214\n",
      "Epoch 407, Weight = 1.987133502960205, Bias = 0.09607776254415512, Training Loss = 0.0018609300022944808, Testing Loss = 0.002646997105330229\n",
      "Epoch 408, Weight = 1.9871840476989746, Bias = 0.09570018947124481, Training Loss = 0.0018463495653122663, Testing Loss = 0.002626218367367983\n",
      "Epoch 409, Weight = 1.987234354019165, Bias = 0.09532409906387329, Training Loss = 0.0018318542279303074, Testing Loss = 0.0026056180940940976\n",
      "Epoch 410, Weight = 1.987284541130066, Bias = 0.09494949132204056, Training Loss = 0.001817492302507162, Testing Loss = 0.002585153153631836\n",
      "Epoch 411, Weight = 1.9873344898223877, Bias = 0.09457635879516602, Training Loss = 0.0018032229272648692, Testing Loss = 0.002564906608313322\n",
      "Epoch 412, Weight = 1.98738431930542, Bias = 0.09420469403266907, Training Loss = 0.0017890780000016093, Testing Loss = 0.002544793300330639\n",
      "Epoch 413, Weight = 1.987433910369873, Bias = 0.09383448213338852, Training Loss = 0.0017750494880601764, Testing Loss = 0.002524827665183693\n",
      "Epoch 414, Weight = 1.987483263015747, Bias = 0.09346571564674377, Training Loss = 0.0017611193470656872, Testing Loss = 0.002505020529497415\n",
      "Epoch 415, Weight = 1.987532377243042, Bias = 0.09309840947389603, Training Loss = 0.0017473066691309214, Testing Loss = 0.002485332661308348\n",
      "Epoch 416, Weight = 1.987581491470337, Bias = 0.09273255616426468, Training Loss = 0.0017336111050099134, Testing Loss = 0.0024658693582750857\n",
      "Epoch 417, Weight = 1.9876302480697632, Bias = 0.09236812591552734, Training Loss = 0.001719991210848093, Testing Loss = 0.0024464825983159244\n",
      "Epoch 418, Weight = 1.9876788854599, Bias = 0.09200513362884521, Training Loss = 0.001706514973193407, Testing Loss = 0.0024273324524983764\n",
      "Epoch 419, Weight = 1.9877272844314575, Bias = 0.0916435644030571, Training Loss = 0.0016931128920987248, Testing Loss = 0.0024082838208414614\n",
      "Epoch 420, Weight = 1.987775444984436, Bias = 0.091283418238163, Training Loss = 0.0016798228025436401, Testing Loss = 0.0023893621983006597\n",
      "Epoch 421, Weight = 1.987823486328125, Bias = 0.0909246951341629, Training Loss = 0.0016666678711771965, Testing Loss = 0.002370607398916036\n",
      "Epoch 422, Weight = 1.9878714084625244, Bias = 0.09056738764047623, Training Loss = 0.0016535775503143668, Testing Loss = 0.002352084149606526\n",
      "Epoch 423, Weight = 1.9879190921783447, Bias = 0.09021147340536118, Training Loss = 0.0016406361246481538, Testing Loss = 0.0023336336598731577\n",
      "Epoch 424, Weight = 1.987966537475586, Bias = 0.08985694497823715, Training Loss = 0.0016277492977678776, Testing Loss = 0.0023153069778345525\n",
      "Epoch 425, Weight = 1.988013744354248, Bias = 0.08950381726026535, Training Loss = 0.001614979119040072, Testing Loss = 0.002297117724083364\n",
      "Epoch 426, Weight = 1.9880608320236206, Bias = 0.08915208280086517, Training Loss = 0.0016023016069084406, Testing Loss = 0.00227905111387372\n",
      "Epoch 427, Weight = 1.9881079196929932, Bias = 0.08880174905061722, Training Loss = 0.001589752035215497, Testing Loss = 0.002261261106468737\n",
      "Epoch 428, Weight = 1.9881545305252075, Bias = 0.0884527638554573, Training Loss = 0.0015772690530866385, Testing Loss = 0.0022434904240071774\n",
      "Epoch 429, Weight = 1.9882011413574219, Bias = 0.08810516446828842, Training Loss = 0.0015648823464289308, Testing Loss = 0.0022259041434153914\n",
      "Epoch 430, Weight = 1.9882475137710571, Bias = 0.08775892853736877, Training Loss = 0.0015526360366493464, Testing Loss = 0.002208437188528478\n",
      "Epoch 431, Weight = 1.9882936477661133, Bias = 0.08741404861211777, Training Loss = 0.0015404410660266876, Testing Loss = 0.002191102597862482\n",
      "Epoch 432, Weight = 1.9883397817611694, Bias = 0.087070532143116, Training Loss = 0.0015283683314919472, Testing Loss = 0.002173963177483529\n",
      "Epoch 433, Weight = 1.988385558128357, Bias = 0.08672834932804108, Training Loss = 0.0015163755742833018, Testing Loss = 0.002156902162823826\n",
      "Epoch 434, Weight = 1.9884310960769653, Bias = 0.0863875150680542, Training Loss = 0.0015044675674289465, Testing Loss = 0.002139932883437723\n",
      "Epoch 435, Weight = 1.9884765148162842, Bias = 0.08604802936315536, Training Loss = 0.001492672716267407, Testing Loss = 0.002123131533153355\n",
      "Epoch 436, Weight = 1.988521933555603, Bias = 0.08570988476276398, Training Loss = 0.0014809693675488234, Testing Loss = 0.0021065319888293743\n",
      "Epoch 437, Weight = 1.9885669946670532, Bias = 0.08537305146455765, Training Loss = 0.001469334471039474, Testing Loss = 0.0020899976952932775\n",
      "Epoch 438, Weight = 1.9886119365692139, Bias = 0.08503755182027817, Training Loss = 0.0014578294940292835, Testing Loss = 0.002073576964903623\n",
      "Epoch 439, Weight = 1.988656759262085, Bias = 0.08470337837934494, Training Loss = 0.001446388429030776, Testing Loss = 0.0020573444780893624\n",
      "Epoch 440, Weight = 1.9887012243270874, Bias = 0.08437050133943558, Training Loss = 0.0014350397977977991, Testing Loss = 0.002041162399109453\n",
      "Epoch 441, Weight = 1.9887456893920898, Bias = 0.08403894305229187, Training Loss = 0.001423790818080306, Testing Loss = 0.0020251665264368057\n",
      "Epoch 442, Weight = 1.9887897968292236, Bias = 0.08370868116617203, Training Loss = 0.001412599696777761, Testing Loss = 0.0020092814811505377\n",
      "Epoch 443, Weight = 1.9888339042663574, Bias = 0.08337973058223724, Training Loss = 0.0014015514170750976, Testing Loss = 0.0019935195450671017\n",
      "Epoch 444, Weight = 1.988877773284912, Bias = 0.08305206149816513, Training Loss = 0.001390537479892373, Testing Loss = 0.001977867155801505\n",
      "Epoch 445, Weight = 1.9889215230941772, Bias = 0.08272568881511688, Training Loss = 0.0013796327402815223, Testing Loss = 0.0019623732659965754\n",
      "Epoch 446, Weight = 1.9889650344848633, Bias = 0.0824005976319313, Training Loss = 0.001368813798762858, Testing Loss = 0.0019469744293019176\n",
      "Epoch 447, Weight = 1.9890084266662598, Bias = 0.0820767804980278, Training Loss = 0.0013580721570178866, Testing Loss = 0.0019317088299430907\n",
      "Epoch 448, Weight = 1.9890515804290771, Bias = 0.08175423741340637, Training Loss = 0.0013474257430061698, Testing Loss = 0.001916549983434379\n",
      "Epoch 449, Weight = 1.989094614982605, Bias = 0.08143295347690582, Training Loss = 0.0013368480140343308, Testing Loss = 0.0019014972494915128\n",
      "Epoch 450, Weight = 1.9891375303268433, Bias = 0.08111294358968735, Training Loss = 0.0013263801811262965, Testing Loss = 0.0018866221071220934\n",
      "Epoch 451, Weight = 1.9891802072525024, Bias = 0.08079418540000916, Training Loss = 0.0013159604277461767, Testing Loss = 0.001871815591584891\n",
      "Epoch 452, Weight = 1.989222764968872, Bias = 0.08047667890787125, Training Loss = 0.0013056499883532524, Testing Loss = 0.0018571617547422647\n",
      "Epoch 453, Weight = 1.9892650842666626, Bias = 0.08016040921211243, Training Loss = 0.0012954020639881492, Testing Loss = 0.001842588244471699\n",
      "Epoch 454, Weight = 1.9893072843551636, Bias = 0.07984539866447449, Training Loss = 0.0012852420331910253, Testing Loss = 0.001828095002565533\n",
      "Epoch 455, Weight = 1.989349365234375, Bias = 0.07953162491321564, Training Loss = 0.0012751556932926178, Testing Loss = 0.001813797338400036\n",
      "Epoch 456, Weight = 1.9893912076950073, Bias = 0.07921907305717468, Training Loss = 0.001265164464712143, Testing Loss = 0.0017995559610426426\n",
      "Epoch 457, Weight = 1.9894328117370605, Bias = 0.07890775054693222, Training Loss = 0.0012552221305668354, Testing Loss = 0.0017854382167570293\n",
      "Epoch 458, Weight = 1.9894742965698242, Bias = 0.07859765738248825, Training Loss = 0.0012453895760700107, Testing Loss = 0.0017714108107611537\n",
      "Epoch 459, Weight = 1.9895156621932983, Bias = 0.07828877866268158, Training Loss = 0.0012356059160083532, Testing Loss = 0.0017574834637343884\n",
      "Epoch 460, Weight = 1.989556908607483, Bias = 0.07798111438751221, Training Loss = 0.0012259157374501228, Testing Loss = 0.0017437468050047755\n",
      "Epoch 461, Weight = 1.9895979166030884, Bias = 0.07767466455698013, Training Loss = 0.0012162997154518962, Testing Loss = 0.0017300518229603767\n",
      "Epoch 462, Weight = 1.9896388053894043, Bias = 0.07736942172050476, Training Loss = 0.0012067642528563738, Testing Loss = 0.0017164793680422008\n",
      "Epoch 463, Weight = 1.9896794557571411, Bias = 0.0770653709769249, Training Loss = 0.0011972894426435232, Testing Loss = 0.0017029921291396022\n",
      "Epoch 464, Weight = 1.989720106124878, Bias = 0.07676252722740173, Training Loss = 0.0011879089288413525, Testing Loss = 0.0016896481392905116\n",
      "Epoch 465, Weight = 1.9897605180740356, Bias = 0.07646086812019348, Training Loss = 0.0011785777751356363, Testing Loss = 0.0016764338943175972\n",
      "Epoch 466, Weight = 1.9898006916046143, Bias = 0.07616037875413895, Training Loss = 0.0011693363776430488, Testing Loss = 0.0016632596962153912\n",
      "Epoch 467, Weight = 1.9898407459259033, Bias = 0.07586108893156052, Training Loss = 0.001160172512754798, Testing Loss = 0.001650192600209266\n",
      "Epoch 468, Weight = 1.9898808002471924, Bias = 0.0755629763007164, Training Loss = 0.0011510674376040697, Testing Loss = 0.0016373087419196963\n",
      "Epoch 469, Weight = 1.9899204969406128, Bias = 0.07526601105928421, Training Loss = 0.0011420403607189655, Testing Loss = 0.0016244204598478973\n",
      "Epoch 470, Weight = 1.9899601936340332, Bias = 0.07497023791074753, Training Loss = 0.0011330840643495321, Testing Loss = 0.001611701911315322\n",
      "Epoch 471, Weight = 1.9899996519088745, Bias = 0.07467561215162277, Training Loss = 0.0011241992469877005, Testing Loss = 0.0015990663086995482\n",
      "Epoch 472, Weight = 1.9900388717651367, Bias = 0.07438214123249054, Training Loss = 0.0011153733357787132, Testing Loss = 0.0015864900196902454\n",
      "Epoch 473, Weight = 1.9900779724121094, Bias = 0.07408983260393143, Training Loss = 0.0011066135484725237, Testing Loss = 0.0015740501694381237\n",
      "Epoch 474, Weight = 1.990117073059082, Bias = 0.07379867881536484, Training Loss = 0.0010979562066495419, Testing Loss = 0.0015617339522577822\n",
      "Epoch 475, Weight = 1.990155816078186, Bias = 0.07350865006446838, Training Loss = 0.0010893353028222919, Testing Loss = 0.0015494546387344599\n",
      "Epoch 476, Weight = 1.99019455909729, Bias = 0.07321978360414505, Training Loss = 0.0010807792423292994, Testing Loss = 0.00153733033221215\n",
      "Epoch 477, Weight = 1.990233063697815, Bias = 0.07293204218149185, Training Loss = 0.0010723231825977564, Testing Loss = 0.0015252422308549285\n",
      "Epoch 478, Weight = 1.9902714490890503, Bias = 0.07264543324708939, Training Loss = 0.0010639084503054619, Testing Loss = 0.0015132868429645896\n",
      "Epoch 479, Weight = 1.990309715270996, Bias = 0.07235995680093765, Training Loss = 0.0010555556509643793, Testing Loss = 0.0015014198143035173\n",
      "Epoch 480, Weight = 1.9903477430343628, Bias = 0.07207559049129486, Training Loss = 0.001047281315550208, Testing Loss = 0.0014895994681864977\n",
      "Epoch 481, Weight = 1.9903857707977295, Bias = 0.0717923566699028, Training Loss = 0.001039066817611456, Testing Loss = 0.0014779508346691728\n",
      "Epoch 482, Weight = 1.9904234409332275, Bias = 0.07151021808385849, Training Loss = 0.0010309037752449512, Testing Loss = 0.0014663570909760892\n",
      "Epoch 483, Weight = 1.9904611110687256, Bias = 0.07122919708490372, Training Loss = 0.0010228281607851386, Testing Loss = 0.0014548202161677182\n",
      "Epoch 484, Weight = 1.9904985427856445, Bias = 0.07094927877187729, Training Loss = 0.0010147819994017482, Testing Loss = 0.0014434210606850684\n",
      "Epoch 485, Weight = 1.9905359745025635, Bias = 0.0706704631447792, Training Loss = 0.0010068390984088182, Testing Loss = 0.0014321271446533501\n",
      "Epoch 486, Weight = 1.9905731678009033, Bias = 0.07039273530244827, Training Loss = 0.0009989351965487003, Testing Loss = 0.0014208888169378042\n",
      "Epoch 487, Weight = 1.9906102418899536, Bias = 0.07011610269546509, Training Loss = 0.0009911045199260116, Testing Loss = 0.001409765740390867\n",
      "Epoch 488, Weight = 1.9906470775604248, Bias = 0.06984054297208786, Training Loss = 0.0009833279764279723, Testing Loss = 0.0013986554113216698\n",
      "Epoch 489, Weight = 1.9906837940216064, Bias = 0.06956607848405838, Training Loss = 0.0009756024810485542, Testing Loss = 0.0013876992743462324\n",
      "Epoch 490, Weight = 1.9907203912734985, Bias = 0.06929270178079605, Training Loss = 0.0009679556242190301, Testing Loss = 0.0013767970958724618\n",
      "Epoch 491, Weight = 1.9907569885253906, Bias = 0.06902040541172028, Training Loss = 0.0009603824000805616, Testing Loss = 0.001366027514450252\n",
      "Epoch 492, Weight = 1.990793228149414, Bias = 0.06874915957450867, Training Loss = 0.0009528272785246372, Testing Loss = 0.0013553002499975264\n",
      "Epoch 493, Weight = 1.9908294677734375, Bias = 0.06847898662090302, Training Loss = 0.0009453687816858292, Testing Loss = 0.0013446738594211638\n",
      "Epoch 494, Weight = 1.9908654689788818, Bias = 0.06820987164974213, Training Loss = 0.0009379396215081215, Testing Loss = 0.001334100030362606\n",
      "Epoch 495, Weight = 1.9909013509750366, Bias = 0.067941814661026, Training Loss = 0.000930573558434844, Testing Loss = 0.001323656179010868\n",
      "Epoch 496, Weight = 1.9909371137619019, Bias = 0.06767481565475464, Training Loss = 0.0009232899756170809, Testing Loss = 0.0013132727472111583\n",
      "Epoch 497, Weight = 1.9909727573394775, Bias = 0.06740887463092804, Training Loss = 0.00091604731278494, Testing Loss = 0.001302987802773714\n",
      "Epoch 498, Weight = 1.9910081624984741, Bias = 0.06714396923780441, Training Loss = 0.0009088574443012476, Testing Loss = 0.00129273472703062\n",
      "Epoch 499, Weight = 1.9910434484481812, Bias = 0.06688009947538376, Training Loss = 0.0009017352713271976, Testing Loss = 0.00128257941105403\n",
      "Epoch 500, Weight = 1.9910787343978882, Bias = 0.06661728769540787, Training Loss = 0.0008946629823185503, Testing Loss = 0.0012725611741188914\n",
      "Epoch 501, Weight = 1.9911137819290161, Bias = 0.06635548919439316, Training Loss = 0.0008876332431100309, Testing Loss = 0.001262571691768244\n",
      "Epoch 502, Weight = 1.9911487102508545, Bias = 0.06609471887350082, Training Loss = 0.0008806836558505893, Testing Loss = 0.001252650865353644\n",
      "Epoch 503, Weight = 1.9911835193634033, Bias = 0.06583498418331146, Training Loss = 0.0008737611351534724, Testing Loss = 0.00124285469064489\n",
      "Epoch 504, Weight = 1.9912182092666626, Bias = 0.06557626277208328, Training Loss = 0.0008669253438711166, Testing Loss = 0.0012330969038885087\n",
      "Epoch 505, Weight = 1.9912526607513428, Bias = 0.06531854718923569, Training Loss = 0.0008601178415119648, Testing Loss = 0.0012233963061589748\n",
      "Epoch 506, Weight = 1.9912869930267334, Bias = 0.06506185978651047, Training Loss = 0.0008533569052815437, Testing Loss = 0.0012137998710386455\n",
      "Epoch 507, Weight = 1.991321325302124, Bias = 0.06480618566274643, Training Loss = 0.0008466721046715975, Testing Loss = 0.0012042883899994195\n",
      "Epoch 508, Weight = 1.9913554191589355, Bias = 0.06455150246620178, Training Loss = 0.000840027118101716, Testing Loss = 0.001194851181935519\n",
      "Epoch 509, Weight = 1.991389274597168, Bias = 0.06429781764745712, Training Loss = 0.0008334298036061227, Testing Loss = 0.0011854511394631118\n",
      "Epoch 510, Weight = 1.9914231300354004, Bias = 0.06404514610767365, Training Loss = 0.000826894014608115, Testing Loss = 0.0011761530477087945\n",
      "Epoch 511, Weight = 1.9914569854736328, Bias = 0.06379347294569016, Training Loss = 0.0008204226614907384, Testing Loss = 0.001166974427178502\n",
      "Epoch 512, Weight = 1.9914904832839966, Bias = 0.06354276835918427, Training Loss = 0.0008139853016473353, Testing Loss = 0.0011578136764001101\n",
      "Epoch 513, Weight = 1.9915238618850708, Bias = 0.06329305469989777, Training Loss = 0.0008075875230133533, Testing Loss = 0.0011487070005387068\n",
      "Epoch 514, Weight = 1.9915571212768555, Bias = 0.06304431706666946, Training Loss = 0.0008012624457478523, Testing Loss = 0.0011397002381272614\n",
      "Epoch 515, Weight = 1.9915903806686401, Bias = 0.06279657781124115, Training Loss = 0.0007949862629175186, Testing Loss = 0.0011307468230370432\n",
      "Epoch 516, Weight = 1.9916235208511353, Bias = 0.06254981458187103, Training Loss = 0.0007887507672421634, Testing Loss = 0.0011219197476748377\n",
      "Epoch 517, Weight = 1.9916564226150513, Bias = 0.06230400130152702, Training Loss = 0.0007825545617379248, Testing Loss = 0.0011131174978800118\n",
      "Epoch 518, Weight = 1.9916892051696777, Bias = 0.062059156596660614, Training Loss = 0.0007764128968119621, Testing Loss = 0.0011043774138670415\n",
      "Epoch 519, Weight = 1.991721749305725, Bias = 0.06181526184082031, Training Loss = 0.0007703197188675404, Testing Loss = 0.0010956795886158943\n",
      "Epoch 520, Weight = 1.991754412651062, Bias = 0.061572350561618805, Training Loss = 0.0007642828859388828, Testing Loss = 0.001087133161490783\n",
      "Epoch 521, Weight = 1.9917868375778198, Bias = 0.06133037805557251, Training Loss = 0.0007582854595966637, Testing Loss = 0.00107859299168922\n",
      "Epoch 522, Weight = 1.9918190240859985, Bias = 0.061089348047971725, Training Loss = 0.000752346939407289, Testing Loss = 0.0010701213905122131\n",
      "Epoch 523, Weight = 1.9918512105941772, Bias = 0.06084928289055824, Training Loss = 0.0007464497466571629, Testing Loss = 0.001061737013515085\n",
      "Epoch 524, Weight = 1.9918831586837769, Bias = 0.060610149055719376, Training Loss = 0.0007405781652778387, Testing Loss = 0.0010533933818805963\n",
      "Epoch 525, Weight = 1.9919151067733765, Bias = 0.06037197634577751, Training Loss = 0.0007347748032771051, Testing Loss = 0.0010451266134623438\n",
      "Epoch 526, Weight = 1.991946816444397, Bias = 0.06013472005724907, Training Loss = 0.0007290177745744586, Testing Loss = 0.0010369267547503114\n",
      "Epoch 527, Weight = 1.9919785261154175, Bias = 0.05989840626716614, Training Loss = 0.0007232953212223947, Testing Loss = 0.0010288121993653476\n",
      "Epoch 528, Weight = 1.9920101165771484, Bias = 0.059663016349077225, Training Loss = 0.00071762315928936, Testing Loss = 0.0010207371378783137\n",
      "Epoch 529, Weight = 1.9920414686203003, Bias = 0.059428539127111435, Training Loss = 0.0007119803922250867, Testing Loss = 0.0010127371933776885\n",
      "Epoch 530, Weight = 1.9920727014541626, Bias = 0.05919499695301056, Training Loss = 0.0007063971133902669, Testing Loss = 0.0010047855612356216\n",
      "Epoch 531, Weight = 1.992103934288025, Bias = 0.058962382376194, Training Loss = 0.0007008634274825454, Testing Loss = 0.0009969082311727107\n",
      "Epoch 532, Weight = 1.992134928703308, Bias = 0.058730658143758774, Training Loss = 0.0006953737465664744, Testing Loss = 0.0009890786895994097\n",
      "Epoch 533, Weight = 1.9921658039093018, Bias = 0.05849985033273697, Training Loss = 0.0006899143336340785, Testing Loss = 0.0009813392534852028\n",
      "Epoch 534, Weight = 1.9921965599060059, Bias = 0.05826994776725769, Training Loss = 0.0006844988092780113, Testing Loss = 0.000973604415776208\n",
      "Epoch 535, Weight = 1.99222731590271, Bias = 0.05804096534848213, Training Loss = 0.0006791263003833592, Testing Loss = 0.0009659846837166697\n",
      "Epoch 536, Weight = 1.992257833480835, Bias = 0.057812873274087906, Training Loss = 0.0006737990770488977, Testing Loss = 0.0009583948994986713\n",
      "Epoch 537, Weight = 1.9922882318496704, Bias = 0.05758567526936531, Training Loss = 0.0006685048574581742, Testing Loss = 0.0009508843068033457\n",
      "Epoch 538, Weight = 1.9923186302185059, Bias = 0.05735938251018524, Training Loss = 0.0006632801960222423, Testing Loss = 0.000943454127991572\n",
      "Epoch 539, Weight = 1.9923486709594727, Bias = 0.05713395029306412, Training Loss = 0.0006580649642273784, Testing Loss = 0.0009360187104903162\n",
      "Epoch 540, Weight = 1.992378830909729, Bias = 0.056909430772066116, Training Loss = 0.0006529052625410259, Testing Loss = 0.0009286956046707928\n",
      "Epoch 541, Weight = 1.9924087524414062, Bias = 0.05668577924370766, Training Loss = 0.0006477852584794164, Testing Loss = 0.0009214013116434216\n",
      "Epoch 542, Weight = 1.992438554763794, Bias = 0.05646301433444023, Training Loss = 0.0006426980835385621, Testing Loss = 0.0009141929040197283\n",
      "Epoch 543, Weight = 1.992468237876892, Bias = 0.056241121143102646, Training Loss = 0.0006376663222908974, Testing Loss = 0.0009069968073163182\n",
      "Epoch 544, Weight = 1.9924978017807007, Bias = 0.0560201033949852, Training Loss = 0.0006326537113636732, Testing Loss = 0.0008998771081678569\n",
      "Epoch 545, Weight = 1.9925273656845093, Bias = 0.05579996481537819, Training Loss = 0.0006276915082708001, Testing Loss = 0.0008928260649554431\n",
      "Epoch 546, Weight = 1.9925566911697388, Bias = 0.05558067560195923, Training Loss = 0.0006227833800949156, Testing Loss = 0.0008858186192810535\n",
      "Epoch 547, Weight = 1.9925860166549683, Bias = 0.05536225438117981, Training Loss = 0.0006178990006446838, Testing Loss = 0.000878879043739289\n",
      "Epoch 548, Weight = 1.9926151037216187, Bias = 0.05514468625187874, Training Loss = 0.0006130493129603565, Testing Loss = 0.0008719825127627701\n",
      "Epoch 549, Weight = 1.9926440715789795, Bias = 0.05492797866463661, Training Loss = 0.0006082229665480554, Testing Loss = 0.0008651131356600672\n",
      "Epoch 550, Weight = 1.9926730394363403, Bias = 0.05471213534474373, Training Loss = 0.0006034621619619429, Testing Loss = 0.0008583576127421111\n",
      "Epoch 551, Weight = 1.992701768875122, Bias = 0.0544971227645874, Training Loss = 0.0005987286567687988, Testing Loss = 0.0008516130328644067\n",
      "Epoch 552, Weight = 1.9927304983139038, Bias = 0.05428297072649002, Training Loss = 0.0005940337432548404, Testing Loss = 0.0008449345477856696\n",
      "Epoch 553, Weight = 1.992759108543396, Bias = 0.054069649428129196, Training Loss = 0.0005893735215067863, Testing Loss = 0.0008383217500522733\n",
      "Epoch 554, Weight = 1.9927875995635986, Bias = 0.053857166320085526, Training Loss = 0.0005847514257766306, Testing Loss = 0.0008317571191582829\n",
      "Epoch 555, Weight = 1.9928158521652222, Bias = 0.05364551022648811, Training Loss = 0.0005801577353850007, Testing Loss = 0.0008252114930655807\n",
      "Epoch 556, Weight = 1.9928441047668457, Bias = 0.05343470349907875, Training Loss = 0.0005756047903560102, Testing Loss = 0.0008187374332919717\n",
      "Epoch 557, Weight = 1.9928723573684692, Bias = 0.053224723786115646, Training Loss = 0.0005711019039154053, Testing Loss = 0.0008123511797748506\n",
      "Epoch 558, Weight = 1.9929002523422241, Bias = 0.05301554128527641, Training Loss = 0.0005666146753355861, Testing Loss = 0.0008059429819695652\n",
      "Epoch 559, Weight = 1.992928147315979, Bias = 0.05280720070004463, Training Loss = 0.0005621795426122844, Testing Loss = 0.0007996370841283351\n",
      "Epoch 560, Weight = 1.9929560422897339, Bias = 0.05259968340396881, Training Loss = 0.0005577621050179005, Testing Loss = 0.000793370942119509\n",
      "Epoch 561, Weight = 1.9929836988449097, Bias = 0.05239297077059746, Training Loss = 0.0005533986259251833, Testing Loss = 0.0007871526468079537\n",
      "Epoch 562, Weight = 1.993011236190796, Bias = 0.05218707025051117, Training Loss = 0.0005490508046932518, Testing Loss = 0.0007809505623299628\n",
      "Epoch 563, Weight = 1.9930386543273926, Bias = 0.051981981843709946, Training Loss = 0.0005447345902211964, Testing Loss = 0.0007748257194180042\n",
      "Epoch 564, Weight = 1.9930660724639893, Bias = 0.05177770182490349, Training Loss = 0.0005404628464020789, Testing Loss = 0.0007687774486839771\n",
      "Epoch 565, Weight = 1.9930932521820068, Bias = 0.0515742190182209, Training Loss = 0.0005362346419133246, Testing Loss = 0.000762700627092272\n",
      "Epoch 566, Weight = 1.9931204319000244, Bias = 0.05137154459953308, Training Loss = 0.0005320116179063916, Testing Loss = 0.0007567519787698984\n",
      "Epoch 567, Weight = 1.9931474924087524, Bias = 0.05116966739296913, Training Loss = 0.0005278580356389284, Testing Loss = 0.0007508266717195511\n",
      "Epoch 568, Weight = 1.993174433708191, Bias = 0.05096857622265816, Training Loss = 0.0005237011355347931, Testing Loss = 0.0007449246186297387\n",
      "Epoch 569, Weight = 1.9932012557983398, Bias = 0.050768282264471054, Training Loss = 0.0005195975536480546, Testing Loss = 0.0007390748360194266\n",
      "Epoch 570, Weight = 1.9932279586791992, Bias = 0.05056877061724663, Training Loss = 0.0005155227845534682, Testing Loss = 0.0007332705426961184\n",
      "Epoch 571, Weight = 1.993254542350769, Bias = 0.05037003755569458, Training Loss = 0.0005114691448397934, Testing Loss = 0.000727517792256549\n",
      "Epoch 572, Weight = 1.9932811260223389, Bias = 0.050172097980976105, Training Loss = 0.0005074742948636413, Testing Loss = 0.0007218242681119591\n",
      "Epoch 573, Weight = 1.9933074712753296, Bias = 0.049974922090768814, Training Loss = 0.000503481482155621, Testing Loss = 0.0007161531248129904\n",
      "Epoch 574, Weight = 1.9933336973190308, Bias = 0.049778521060943604, Training Loss = 0.0004995443159714341, Testing Loss = 0.0007105185359250754\n",
      "Epoch 575, Weight = 1.9933600425720215, Bias = 0.04958290979266167, Training Loss = 0.0004956300836056471, Testing Loss = 0.0007049705891404301\n",
      "Epoch 576, Weight = 1.9933860301971436, Bias = 0.04938804358243942, Training Loss = 0.0004917216137982905, Testing Loss = 0.0006994161813054234\n",
      "Epoch 577, Weight = 1.9934120178222656, Bias = 0.049193959683179855, Training Loss = 0.000487864192109555, Testing Loss = 0.0006939476588740945\n",
      "Epoch 578, Weight = 1.9934378862380981, Bias = 0.049000632017850876, Training Loss = 0.0004840443143621087, Testing Loss = 0.0006884928734507412\n",
      "Epoch 579, Weight = 1.9934637546539307, Bias = 0.04880807176232338, Training Loss = 0.0004802539187949151, Testing Loss = 0.0006831167556811124\n",
      "Epoch 580, Weight = 1.9934895038604736, Bias = 0.04861626401543617, Training Loss = 0.00047649189946241677, Testing Loss = 0.0006777755625080317\n",
      "Epoch 581, Weight = 1.9935150146484375, Bias = 0.04842519387602806, Training Loss = 0.0004727451305370778, Testing Loss = 0.0006724201084580272\n",
      "Epoch 582, Weight = 1.9935405254364014, Bias = 0.04823489114642143, Training Loss = 0.0004690297937486321, Testing Loss = 0.0006671560986433178\n",
      "Epoch 583, Weight = 1.9935659170150757, Bias = 0.0480453297495842, Training Loss = 0.00046535697765648365, Testing Loss = 0.0006619264895562083\n",
      "Epoch 584, Weight = 1.993591070175171, Bias = 0.04785650968551636, Training Loss = 0.00046170008135959506, Testing Loss = 0.0006566962692886591\n",
      "Epoch 585, Weight = 1.9936163425445557, Bias = 0.0476684495806694, Training Loss = 0.00045807455899193883, Testing Loss = 0.0006515834247693419\n",
      "Epoch 586, Weight = 1.9936413764953613, Bias = 0.04748111963272095, Training Loss = 0.000454494176665321, Testing Loss = 0.0006464634498115629\n",
      "Epoch 587, Weight = 1.993666410446167, Bias = 0.047294531017541885, Training Loss = 0.000450928375357762, Testing Loss = 0.000641390637611039\n",
      "Epoch 588, Weight = 1.993691325187683, Bias = 0.04710867255926132, Training Loss = 0.00044739001896232367, Testing Loss = 0.0006363721331581473\n",
      "Epoch 589, Weight = 1.9937161207199097, Bias = 0.04692353680729866, Training Loss = 0.0004438767791725695, Testing Loss = 0.0006313659250736237\n",
      "Epoch 590, Weight = 1.9937407970428467, Bias = 0.046739138662815094, Training Loss = 0.00044040268403477967, Testing Loss = 0.0006264209077926353\n",
      "Epoch 591, Weight = 1.9937653541564941, Bias = 0.04655545577406883, Training Loss = 0.00043694162741303444, Testing Loss = 0.0006215012690518051\n",
      "Epoch 592, Weight = 1.9937899112701416, Bias = 0.046372510492801666, Training Loss = 0.000433526118285954, Testing Loss = 0.0006166347593534738\n",
      "Epoch 593, Weight = 1.99381422996521, Bias = 0.04619026929140091, Training Loss = 0.0004301099688746035, Testing Loss = 0.0006117742450442165\n",
      "Epoch 594, Weight = 1.9938385486602783, Bias = 0.04600875452160835, Training Loss = 0.00042673823190853, Testing Loss = 0.0006069926603231579\n",
      "Epoch 595, Weight = 1.9938627481460571, Bias = 0.045827947556972504, Training Loss = 0.00042339350329712033, Testing Loss = 0.0006022298621246591\n",
      "Epoch 596, Weight = 1.993886947631836, Bias = 0.04564785957336426, Training Loss = 0.00042007421143352985, Testing Loss = 0.0005974988307571039\n",
      "Epoch 597, Weight = 1.9939109086990356, Bias = 0.045468468219041824, Training Loss = 0.00041676958790048957, Testing Loss = 0.0005928195751039311\n",
      "Epoch 598, Weight = 1.9939348697662354, Bias = 0.0452897846698761, Training Loss = 0.00041350250830873847, Testing Loss = 0.0005881845427211374\n",
      "Epoch 599, Weight = 1.9939587116241455, Bias = 0.045111801475286484, Training Loss = 0.0004102686361875385, Testing Loss = 0.0005835548508912325\n",
      "Epoch 600, Weight = 1.9939824342727661, Bias = 0.04493451490998268, Training Loss = 0.00040704067214392126, Testing Loss = 0.000578988969209604\n",
      "Epoch 601, Weight = 1.9940060377120972, Bias = 0.04475792497396469, Training Loss = 0.0004038458864670247, Testing Loss = 0.0005744282680097967\n",
      "Epoch 602, Weight = 1.9940296411514282, Bias = 0.04458204656839371, Training Loss = 0.0004006875096820295, Testing Loss = 0.000569923737202771\n",
      "Epoch 603, Weight = 1.9940531253814697, Bias = 0.04440684616565704, Training Loss = 0.00039754470344632864, Testing Loss = 0.0005654692940879613\n",
      "Epoch 604, Weight = 1.9940764904022217, Bias = 0.044232334941625595, Training Loss = 0.0003944273921661079, Testing Loss = 0.0005610196676570922\n",
      "Epoch 605, Weight = 1.9940998554229736, Bias = 0.04405851662158966, Training Loss = 0.00039133583777584136, Testing Loss = 0.0005566448380704969\n",
      "Epoch 606, Weight = 1.9941229820251465, Bias = 0.04388536140322685, Training Loss = 0.0003882652090396732, Testing Loss = 0.0005522552091861144\n",
      "Epoch 607, Weight = 1.9941459894180298, Bias = 0.04371289163827896, Training Loss = 0.0003852056688629091, Testing Loss = 0.0005479272513184696\n",
      "Epoch 608, Weight = 1.9941691160202026, Bias = 0.04354112222790718, Training Loss = 0.0003821955469902605, Testing Loss = 0.0005436355713754892\n",
      "Epoch 609, Weight = 1.9941920042037964, Bias = 0.04337001219391823, Training Loss = 0.00037919767783023417, Testing Loss = 0.000539366330485791\n",
      "Epoch 610, Weight = 1.9942148923873901, Bias = 0.0431995764374733, Training Loss = 0.0003762296983040869, Testing Loss = 0.0005351521685952321\n",
      "Epoch 611, Weight = 1.9942375421524048, Bias = 0.04302980378270149, Training Loss = 0.0003732741461135447, Testing Loss = 0.0005309477710397914\n",
      "Epoch 612, Weight = 1.9942601919174194, Bias = 0.04286070540547371, Training Loss = 0.0003703459515236318, Testing Loss = 0.0005267599190119654\n",
      "Epoch 613, Weight = 1.9942827224731445, Bias = 0.04269227012991905, Training Loss = 0.00036744141834788024, Testing Loss = 0.0005226319190114737\n",
      "Epoch 614, Weight = 1.9943052530288696, Bias = 0.04252450168132782, Training Loss = 0.0003645546967163682, Testing Loss = 0.0005185511254239827\n",
      "Epoch 615, Weight = 1.9943276643753052, Bias = 0.04235738515853882, Training Loss = 0.0003616945177782327, Testing Loss = 0.0005144796596141532\n",
      "Epoch 616, Weight = 1.9943498373031616, Bias = 0.04219091683626175, Training Loss = 0.0003588580002542585, Testing Loss = 0.0005104308947920799\n",
      "Epoch 617, Weight = 1.9943721294403076, Bias = 0.0420251227915287, Training Loss = 0.0003560412733349949, Testing Loss = 0.0005064406723249704\n",
      "Epoch 618, Weight = 1.9943941831588745, Bias = 0.04185996577143669, Training Loss = 0.0003532535629346967, Testing Loss = 0.0005024595593567938\n",
      "Epoch 619, Weight = 1.9944162368774414, Bias = 0.04169547185301781, Training Loss = 0.0003504749038256705, Testing Loss = 0.0004985244740964845\n",
      "Epoch 620, Weight = 1.9944381713867188, Bias = 0.04153161868453026, Training Loss = 0.00034773649531416595, Testing Loss = 0.0004946048720739782\n",
      "Epoch 621, Weight = 1.9944599866867065, Bias = 0.041368402540683746, Training Loss = 0.00034499529283493757, Testing Loss = 0.0004907125694444403\n",
      "Epoch 622, Weight = 1.9944818019866943, Bias = 0.041205838322639465, Training Loss = 0.00034229428274556994, Testing Loss = 0.000486865610582754\n",
      "Epoch 623, Weight = 1.9945034980773926, Bias = 0.04104390740394592, Training Loss = 0.00033960334258154035, Testing Loss = 0.0004830636898986995\n",
      "Epoch 624, Weight = 1.9945250749588013, Bias = 0.04088260978460312, Training Loss = 0.0003369489568285644, Testing Loss = 0.0004792702093254775\n",
      "Epoch 625, Weight = 1.9945465326309204, Bias = 0.040721941739320755, Training Loss = 0.0003343104908708483, Testing Loss = 0.00047550971794407815\n",
      "Epoch 626, Weight = 1.9945679903030396, Bias = 0.040561921894550323, Training Loss = 0.000331684947013855, Testing Loss = 0.0004717871925095096\n",
      "Epoch 627, Weight = 1.9945893287658691, Bias = 0.040402524173259735, Training Loss = 0.0003290778258815408, Testing Loss = 0.00046806778118479997\n",
      "Epoch 628, Weight = 1.9946106672286987, Bias = 0.04024375602602959, Training Loss = 0.00032649392960593104, Testing Loss = 0.00046440384176094085\n",
      "Epoch 629, Weight = 1.9946318864822388, Bias = 0.040085602551698685, Training Loss = 0.0003239431243855506, Testing Loss = 0.0004607771697919816\n",
      "Epoch 630, Weight = 1.9946528673171997, Bias = 0.03992806375026703, Training Loss = 0.0003214006428606808, Testing Loss = 0.00045714195584878325\n",
      "Epoch 631, Weight = 1.9946738481521606, Bias = 0.039771150797605515, Training Loss = 0.00031887521618045866, Testing Loss = 0.00045356142800301313\n",
      "Epoch 632, Weight = 1.9946948289871216, Bias = 0.03961485996842384, Training Loss = 0.0003163694345857948, Testing Loss = 0.0004500062786974013\n",
      "Epoch 633, Weight = 1.994715690612793, Bias = 0.03945917636156082, Training Loss = 0.00031388597562909126, Testing Loss = 0.0004464763915166259\n",
      "Epoch 634, Weight = 1.9947364330291748, Bias = 0.039304107427597046, Training Loss = 0.0003114281571470201, Testing Loss = 0.00044296038686297834\n",
      "Epoch 635, Weight = 1.9947571754455566, Bias = 0.039149656891822815, Training Loss = 0.00030898128170520067, Testing Loss = 0.00043949796236120164\n",
      "Epoch 636, Weight = 1.994777798652649, Bias = 0.038995806127786636, Training Loss = 0.00030656217131763697, Testing Loss = 0.00043606635881587863\n",
      "Epoch 637, Weight = 1.994798183441162, Bias = 0.03884254768490791, Training Loss = 0.0003041572927031666, Testing Loss = 0.0004326138296164572\n",
      "Epoch 638, Weight = 1.9948186874389648, Bias = 0.03868991136550903, Training Loss = 0.00030176431755535305, Testing Loss = 0.0004292313533369452\n",
      "Epoch 639, Weight = 1.994839072227478, Bias = 0.03853786736726761, Training Loss = 0.00029939887463115156, Testing Loss = 0.00042586217750795186\n",
      "Epoch 640, Weight = 1.9948593378067017, Bias = 0.03838641569018364, Training Loss = 0.00029705354245379567, Testing Loss = 0.0004225341835990548\n",
      "Epoch 641, Weight = 1.9948796033859253, Bias = 0.03823556378483772, Training Loss = 0.000294724537525326, Testing Loss = 0.0004192132328171283\n",
      "Epoch 642, Weight = 1.9948997497558594, Bias = 0.03808530792593956, Training Loss = 0.000292418320896104, Testing Loss = 0.0004159331292612478\n",
      "Epoch 643, Weight = 1.994919776916504, Bias = 0.03793563321232796, Training Loss = 0.0002901158295571804, Testing Loss = 0.00041266590415034443\n",
      "Epoch 644, Weight = 1.9949398040771484, Bias = 0.03778655454516411, Training Loss = 0.0002878480008803308, Testing Loss = 0.00040943906060419977\n",
      "Epoch 645, Weight = 1.9949595928192139, Bias = 0.03763804957270622, Training Loss = 0.00028558543999679387, Testing Loss = 0.0004062082152813673\n",
      "Epoch 646, Weight = 1.9949795007705688, Bias = 0.03749014437198639, Training Loss = 0.00028334613307379186, Testing Loss = 0.0004030554846394807\n",
      "Epoch 647, Weight = 1.9949991703033447, Bias = 0.037342801690101624, Training Loss = 0.00028112129075452685, Testing Loss = 0.0003998878091806546\n",
      "Epoch 648, Weight = 1.9950188398361206, Bias = 0.037196047604084015, Training Loss = 0.0002789268037304282, Testing Loss = 0.00039673264836892486\n",
      "Epoch 649, Weight = 1.995038390159607, Bias = 0.03704987093806267, Training Loss = 0.0002767346741165966, Testing Loss = 0.00039361695235129446\n",
      "Epoch 650, Weight = 1.9950578212738037, Bias = 0.03690426051616669, Training Loss = 0.0002745606761891395, Testing Loss = 0.00039052407373674214\n",
      "Epoch 651, Weight = 1.9950772523880005, Bias = 0.03675923869013786, Training Loss = 0.0002724095538724214, Testing Loss = 0.0003874643734889105\n",
      "Epoch 652, Weight = 1.9950965642929077, Bias = 0.03661477938294411, Training Loss = 0.0002702711499296129, Testing Loss = 0.0003844224556814879\n",
      "Epoch 653, Weight = 1.995115876197815, Bias = 0.036470893770456314, Training Loss = 0.00026814191369339824, Testing Loss = 0.0003814133378909901\n",
      "Epoch 654, Weight = 1.9951350688934326, Bias = 0.03632756695151329, Training Loss = 0.00026605272432789207, Testing Loss = 0.0003784056898439303\n",
      "Epoch 655, Weight = 1.9951542615890503, Bias = 0.03618481382727623, Training Loss = 0.00026395730674266815, Testing Loss = 0.00037545693339779973\n",
      "Epoch 656, Weight = 1.9951732158660889, Bias = 0.03604260832071304, Training Loss = 0.00026189530035480857, Testing Loss = 0.0003724934649653733\n",
      "Epoch 657, Weight = 1.9951921701431274, Bias = 0.03590097278356552, Training Loss = 0.00025983015075325966, Testing Loss = 0.00036957813426852226\n",
      "Epoch 658, Weight = 1.995211124420166, Bias = 0.03575989603996277, Training Loss = 0.0002577993436716497, Testing Loss = 0.000366690059308894\n",
      "Epoch 659, Weight = 1.995229959487915, Bias = 0.03561937063932419, Training Loss = 0.0002557813422754407, Testing Loss = 0.0003638234920799732\n",
      "Epoch 660, Weight = 1.9952486753463745, Bias = 0.035479385405778885, Training Loss = 0.00025376782286912203, Testing Loss = 0.0003609524719649926\n",
      "Epoch 661, Weight = 1.995267391204834, Bias = 0.03533996641635895, Training Loss = 0.00025178323267027736, Testing Loss = 0.0003581342025427148\n",
      "Epoch 662, Weight = 1.9952858686447144, Bias = 0.03520107641816139, Training Loss = 0.0002498036192264408, Testing Loss = 0.00035531136381905526\n",
      "Epoch 663, Weight = 1.9953044652938843, Bias = 0.035062748938798904, Training Loss = 0.00024784059496596456, Testing Loss = 0.00035251972440164536\n",
      "Epoch 664, Weight = 1.9953229427337646, Bias = 0.0349249541759491, Training Loss = 0.0002458946546539664, Testing Loss = 0.00034975454036612064\n",
      "Epoch 665, Weight = 1.9953413009643555, Bias = 0.034787703305482864, Training Loss = 0.00024396309163421392, Testing Loss = 0.00034702559059951454\n",
      "Epoch 666, Weight = 1.9953595399856567, Bias = 0.03465098515152931, Training Loss = 0.0002420530072413385, Testing Loss = 0.0003442919842200354\n",
      "Epoch 667, Weight = 1.995377779006958, Bias = 0.03451481834053993, Training Loss = 0.0002401545934844762, Testing Loss = 0.00034158886410295963\n",
      "Epoch 668, Weight = 1.9953960180282593, Bias = 0.03437918797135353, Training Loss = 0.00023827014956623316, Testing Loss = 0.0003389170451555401\n",
      "Epoch 669, Weight = 1.9954140186309814, Bias = 0.034244079142808914, Training Loss = 0.00023639772552996874, Testing Loss = 0.000336260098265484\n",
      "Epoch 670, Weight = 1.9954320192337036, Bias = 0.034109506756067276, Training Loss = 0.0002345496031921357, Testing Loss = 0.0003336135996505618\n",
      "Epoch 671, Weight = 1.9954500198364258, Bias = 0.033975474536418915, Training Loss = 0.00023270660312846303, Testing Loss = 0.00033100228756666183\n",
      "Epoch 672, Weight = 1.9954679012298584, Bias = 0.03384196385741234, Training Loss = 0.00023088601301424205, Testing Loss = 0.00032840123458299786\n",
      "Epoch 673, Weight = 1.995485782623291, Bias = 0.033708974719047546, Training Loss = 0.00022907125821802765, Testing Loss = 0.0003258296783315018\n",
      "Epoch 674, Weight = 1.995503544807434, Bias = 0.03357651084661484, Training Loss = 0.00022727999021299183, Testing Loss = 0.0003232831149944104\n",
      "Epoch 675, Weight = 1.995521068572998, Bias = 0.03344454616308212, Training Loss = 0.0002254952269140631, Testing Loss = 0.00032072217436507344\n",
      "Epoch 676, Weight = 1.9955387115478516, Bias = 0.033313121646642685, Training Loss = 0.00022371798695530742, Testing Loss = 0.00031821467564441264\n",
      "Epoch 677, Weight = 1.9955562353134155, Bias = 0.03318221494555473, Training Loss = 0.00022196603822521865, Testing Loss = 0.0003157222454319708\n",
      "Epoch 678, Weight = 1.9955737590789795, Bias = 0.03305181860923767, Training Loss = 0.00022022872872184962, Testing Loss = 0.0003132438359898515\n",
      "Epoch 679, Weight = 1.995591163635254, Bias = 0.0329219326376915, Training Loss = 0.00021849703625775874, Testing Loss = 0.00031078977190190926\n",
      "Epoch 680, Weight = 1.9956084489822388, Bias = 0.032792553305625916, Training Loss = 0.00021678459597751498, Testing Loss = 0.0003083547198912129\n",
      "Epoch 681, Weight = 1.9956257343292236, Bias = 0.03266368806362152, Training Loss = 0.0002150803047697991, Testing Loss = 0.0003059385489905253\n",
      "Epoch 682, Weight = 1.995642900466919, Bias = 0.03253532946109772, Training Loss = 0.0002134002570528537, Testing Loss = 0.00030354630143847317\n",
      "Epoch 683, Weight = 1.9956600666046143, Bias = 0.03240747004747391, Training Loss = 0.00021172741253394634, Testing Loss = 0.00030116344714770094\n",
      "Epoch 684, Weight = 1.99567711353302, Bias = 0.03228010609745979, Training Loss = 0.00021006452152505517, Testing Loss = 0.00029879917565267533\n",
      "Epoch 685, Weight = 1.9956940412521362, Bias = 0.03215324878692627, Training Loss = 0.00020841718651354313, Testing Loss = 0.0002964442319353111\n",
      "Epoch 686, Weight = 1.9957109689712524, Bias = 0.03202689811587334, Training Loss = 0.00020677920838352293, Testing Loss = 0.00029411687137326226\n",
      "Epoch 687, Weight = 1.9957278966903687, Bias = 0.0319010429084301, Training Loss = 0.00020516487711574882, Testing Loss = 0.000291812808427494\n",
      "Epoch 688, Weight = 1.9957447052001953, Bias = 0.03177567198872566, Training Loss = 0.00020355368906166404, Testing Loss = 0.0002895268698921427\n",
      "Epoch 689, Weight = 1.9957613945007324, Bias = 0.03165079280734062, Training Loss = 0.00020194919488858432, Testing Loss = 0.00028725895390380174\n",
      "Epoch 690, Weight = 1.9957780838012695, Bias = 0.03152640908956528, Training Loss = 0.00020036890055052936, Testing Loss = 0.00028501391352619976\n",
      "Epoch 691, Weight = 1.995794653892517, Bias = 0.03140250965952873, Training Loss = 0.00019879997125826776, Testing Loss = 0.00028276377270231023\n",
      "Epoch 692, Weight = 1.995811104774475, Bias = 0.031279098242521286, Training Loss = 0.0001972359896171838, Testing Loss = 0.0002805453332257457\n",
      "Epoch 693, Weight = 1.9958276748657227, Bias = 0.031156184151768684, Training Loss = 0.0001956990163307637, Testing Loss = 0.0002783583040582016\n",
      "Epoch 694, Weight = 1.9958440065383911, Bias = 0.03103373572230339, Training Loss = 0.00019415796850807965, Testing Loss = 0.0002761660871328786\n",
      "Epoch 695, Weight = 1.9958603382110596, Bias = 0.030911773443222046, Training Loss = 0.00019262696150690317, Testing Loss = 0.0002740001800702885\n",
      "Epoch 696, Weight = 1.9958765506744385, Bias = 0.0307902954518795, Training Loss = 0.00019111891742795706, Testing Loss = 0.0002718476462177932\n",
      "Epoch 697, Weight = 1.995892882347107, Bias = 0.030669303610920906, Training Loss = 0.00018962539616040885, Testing Loss = 0.0002697259478736669\n",
      "Epoch 698, Weight = 1.9959089756011963, Bias = 0.030548768118023872, Training Loss = 0.0001881327189039439, Testing Loss = 0.0002676077274372801\n",
      "Epoch 699, Weight = 1.9959250688552856, Bias = 0.03042871691286564, Training Loss = 0.00018666473624762148, Testing Loss = 0.00026550654729362577\n",
      "Epoch 700, Weight = 1.9959410429000854, Bias = 0.030309133231639862, Training Loss = 0.0001851990818977356, Testing Loss = 0.00026341842021793127\n",
      "Epoch 701, Weight = 1.9959570169448853, Bias = 0.030190033838152885, Training Loss = 0.00018373955390416086, Testing Loss = 0.0002613557589938864\n",
      "Epoch 702, Weight = 1.9959728717803955, Bias = 0.03007138893008232, Training Loss = 0.0001823070051614195, Testing Loss = 0.00025930120318662375\n",
      "Epoch 703, Weight = 1.9959887266159058, Bias = 0.02995321713387966, Training Loss = 0.00018087198259308934, Testing Loss = 0.00025726802414283156\n",
      "Epoch 704, Weight = 1.996004581451416, Bias = 0.029835514724254608, Training Loss = 0.00017945421859622002, Testing Loss = 0.00025526837271172553\n",
      "Epoch 705, Weight = 1.9960201978683472, Bias = 0.02971825934946537, Training Loss = 0.0001780518505256623, Testing Loss = 0.00025324642774648964\n",
      "Epoch 706, Weight = 1.9960358142852783, Bias = 0.02960147149860859, Training Loss = 0.0001766484638210386, Testing Loss = 0.00025126249965978786\n",
      "Epoch 707, Weight = 1.9960514307022095, Bias = 0.029485143721103668, Training Loss = 0.00017526069132145494, Testing Loss = 0.00024929943174356595\n",
      "Epoch 708, Weight = 1.996066927909851, Bias = 0.029369274154305458, Training Loss = 0.00017388463311363012, Testing Loss = 0.0002473310596542433\n",
      "Epoch 709, Weight = 1.9960824251174927, Bias = 0.02925386279821396, Training Loss = 0.00017252477118745446, Testing Loss = 0.00024540014419471845\n",
      "Epoch 710, Weight = 1.9960978031158447, Bias = 0.029138892889022827, Training Loss = 0.00017117190873250365, Testing Loss = 0.00024347678117919713\n",
      "Epoch 711, Weight = 1.9961131811141968, Bias = 0.029024384915828705, Training Loss = 0.00016983007662929595, Testing Loss = 0.00024157383450074121\n",
      "Epoch 712, Weight = 1.9961284399032593, Bias = 0.0289103165268898, Training Loss = 0.00016849501116666943, Testing Loss = 0.0002396655545453541\n",
      "Epoch 713, Weight = 1.9961435794830322, Bias = 0.028796695172786713, Training Loss = 0.00016717659309506416, Testing Loss = 0.00023779404000379145\n",
      "Epoch 714, Weight = 1.9961587190628052, Bias = 0.028683526441454887, Training Loss = 0.00016586411220487207, Testing Loss = 0.0002359171412535943\n",
      "Epoch 715, Weight = 1.9961738586425781, Bias = 0.028570806607604027, Training Loss = 0.00016456317098345608, Testing Loss = 0.00023407297703670338\n",
      "Epoch 716, Weight = 1.9961888790130615, Bias = 0.028458528220653534, Training Loss = 0.00016327410412486643, Testing Loss = 0.00023223157040774822\n",
      "Epoch 717, Weight = 1.996203899383545, Bias = 0.028346695005893707, Training Loss = 0.00016199277888517827, Testing Loss = 0.0002304180816281587\n",
      "Epoch 718, Weight = 1.9962186813354492, Bias = 0.028235284611582756, Training Loss = 0.00016071686695795506, Testing Loss = 0.00022859920136397704\n",
      "Epoch 719, Weight = 1.996233582496643, Bias = 0.028124338015913963, Training Loss = 0.0001594611821928993, Testing Loss = 0.00022680799156660214\n",
      "Epoch 720, Weight = 1.996248483657837, Bias = 0.028013817965984344, Training Loss = 0.00015821332635823637, Testing Loss = 0.00022504423395730555\n",
      "Epoch 721, Weight = 1.9962631464004517, Bias = 0.0279037244617939, Training Loss = 0.00015697081107646227, Testing Loss = 0.00022326703765429556\n",
      "Epoch 722, Weight = 1.9962778091430664, Bias = 0.027794072404503822, Training Loss = 0.00015573340351693332, Testing Loss = 0.00022150482254801318\n",
      "Epoch 723, Weight = 1.9962925910949707, Bias = 0.027684859931468964, Training Loss = 0.00015451482613570988, Testing Loss = 0.000219789901166223\n",
      "Epoch 724, Weight = 1.9963070154190063, Bias = 0.027576051652431488, Training Loss = 0.0001533034665044397, Testing Loss = 0.00021804934658575803\n",
      "Epoch 725, Weight = 1.9963215589523315, Bias = 0.02746768482029438, Training Loss = 0.00015210174024105072, Testing Loss = 0.00021633572032442316\n",
      "Epoch 726, Weight = 1.9963361024856567, Bias = 0.027359748259186745, Training Loss = 0.00015090525266714394, Testing Loss = 0.00021465656027430668\n",
      "Epoch 727, Weight = 1.9963504076004028, Bias = 0.027252215892076492, Training Loss = 0.0001497248886153102, Testing Loss = 0.0002129684144165367\n",
      "Epoch 728, Weight = 1.996364712715149, Bias = 0.02714511938393116, Training Loss = 0.00014854950131848454, Testing Loss = 0.0002112826332449913\n",
      "Epoch 729, Weight = 1.996379017829895, Bias = 0.027038441970944405, Training Loss = 0.00014738085155840963, Testing Loss = 0.00020963096903869882\n",
      "Epoch 730, Weight = 1.9963932037353516, Bias = 0.026932185515761375, Training Loss = 0.0001462259970139712, Testing Loss = 0.0002079780970234424\n",
      "Epoch 731, Weight = 1.9964075088500977, Bias = 0.026826363056898117, Training Loss = 0.00014508047024719417, Testing Loss = 0.0002063589490717277\n",
      "Epoch 732, Weight = 1.9964215755462646, Bias = 0.026720939204096794, Training Loss = 0.00014393986202776432, Testing Loss = 0.00020473850599955767\n",
      "Epoch 733, Weight = 1.9964356422424316, Bias = 0.026615934446454048, Training Loss = 0.00014281523181125522, Testing Loss = 0.00020313964341767132\n",
      "Epoch 734, Weight = 1.9964497089385986, Bias = 0.02651134505867958, Training Loss = 0.00014169822679832578, Testing Loss = 0.00020154704543529078\n",
      "Epoch 735, Weight = 1.9964635372161865, Bias = 0.0264071486890316, Training Loss = 0.00014057762746233493, Testing Loss = 0.00019995317416032776\n",
      "Epoch 736, Weight = 1.996477484703064, Bias = 0.026303378865122795, Training Loss = 0.0001394777063978836, Testing Loss = 0.00019839227752527222\n",
      "Epoch 737, Weight = 1.9964913129806519, Bias = 0.026200005784630775, Training Loss = 0.00013838049198966473, Testing Loss = 0.0001968259093700908\n",
      "Epoch 738, Weight = 1.9965051412582397, Bias = 0.026097051799297333, Training Loss = 0.00013730218051932752, Testing Loss = 0.00019528474513208494\n",
      "Epoch 739, Weight = 1.996518850326538, Bias = 0.025994494557380676, Training Loss = 0.00013622449478134513, Testing Loss = 0.00019374964176677167\n",
      "Epoch 740, Weight = 1.9965325593948364, Bias = 0.025892339646816254, Training Loss = 0.00013514758029486984, Testing Loss = 0.00019224682910135016\n",
      "Epoch 741, Weight = 1.9965461492538452, Bias = 0.025790581479668617, Training Loss = 0.00013409234816208482, Testing Loss = 0.00019073109433520585\n",
      "Epoch 742, Weight = 1.996559739112854, Bias = 0.025689231231808662, Training Loss = 0.0001330359373241663, Testing Loss = 0.0001892400614451617\n",
      "Epoch 743, Weight = 1.9965732097625732, Bias = 0.025588274002075195, Training Loss = 0.0001319948205491528, Testing Loss = 0.00018773624469758943\n",
      "Epoch 744, Weight = 1.9965866804122925, Bias = 0.02548772282898426, Training Loss = 0.0001309596555074677, Testing Loss = 0.00018627152167027816\n",
      "Epoch 745, Weight = 1.9966001510620117, Bias = 0.025387566536664963, Training Loss = 0.0001299351715715602, Testing Loss = 0.0001848237807280384\n",
      "Epoch 746, Weight = 1.9966135025024414, Bias = 0.025287795811891556, Training Loss = 0.00012891831283923239, Testing Loss = 0.00018336327775614336\n",
      "Epoch 747, Weight = 1.996626853942871, Bias = 0.025188425555825233, Training Loss = 0.00012790523760486394, Testing Loss = 0.00018193409050581977\n",
      "Epoch 748, Weight = 1.9966400861740112, Bias = 0.025089431554079056, Training Loss = 0.00012690003495663404, Testing Loss = 0.00018050333892460912\n",
      "Epoch 749, Weight = 1.9966533184051514, Bias = 0.024990838021039963, Training Loss = 0.00012590594997163862, Testing Loss = 0.0001790924943634309\n",
      "Epoch 750, Weight = 1.996666431427002, Bias = 0.024892626330256462, Training Loss = 0.00012492157111410052, Testing Loss = 0.00017768717953003943\n",
      "Epoch 751, Weight = 1.9966795444488525, Bias = 0.024794802069664, Training Loss = 0.00012394040822982788, Testing Loss = 0.00017628740170039237\n",
      "Epoch 752, Weight = 1.9966925382614136, Bias = 0.024697359651327133, Training Loss = 0.00012296324712224305, Testing Loss = 0.0001749040966387838\n",
      "Epoch 753, Weight = 1.9967055320739746, Bias = 0.024600308388471603, Training Loss = 0.0001220008052769117, Testing Loss = 0.0001735293844831176\n",
      "Epoch 754, Weight = 1.9967185258865356, Bias = 0.024503633379936218, Training Loss = 0.00012104011693736538, Testing Loss = 0.00017217094136867672\n",
      "Epoch 755, Weight = 1.9967314004898071, Bias = 0.024407334625720978, Training Loss = 0.00012009358033537865, Testing Loss = 0.00017081784608308226\n",
      "Epoch 756, Weight = 1.9967442750930786, Bias = 0.024311425164341927, Training Loss = 0.00011915471259271726, Testing Loss = 0.0001694877864792943\n",
      "Epoch 757, Weight = 1.9967570304870605, Bias = 0.024215884506702423, Training Loss = 0.00011821619409602135, Testing Loss = 0.0001681452849879861\n",
      "Epoch 758, Weight = 1.9967697858810425, Bias = 0.024120721966028214, Training Loss = 0.00011728855315595865, Testing Loss = 0.00016683257126715034\n",
      "Epoch 759, Weight = 1.9967825412750244, Bias = 0.024025943130254745, Training Loss = 0.00011637030547717586, Testing Loss = 0.00016553184832446277\n",
      "Epoch 760, Weight = 1.9967950582504272, Bias = 0.023931516334414482, Training Loss = 0.00011545608867891133, Testing Loss = 0.00016422256885562092\n",
      "Epoch 761, Weight = 1.9968076944351196, Bias = 0.023837478831410408, Training Loss = 0.00011455399362603202, Testing Loss = 0.00016293888620566577\n",
      "Epoch 762, Weight = 1.996820330619812, Bias = 0.023743808269500732, Training Loss = 0.00011364996316842735, Testing Loss = 0.00016166397836059332\n",
      "Epoch 763, Weight = 1.9968328475952148, Bias = 0.02365049533545971, Training Loss = 0.00011276062286924571, Testing Loss = 0.00016039709953474812\n",
      "Epoch 764, Weight = 1.9968452453613281, Bias = 0.023557541891932487, Training Loss = 0.00011187372729182243, Testing Loss = 0.00015913891547825187\n",
      "Epoch 765, Weight = 1.9968576431274414, Bias = 0.023464959114789963, Training Loss = 0.00011099995754193515, Testing Loss = 0.00015789238386787474\n",
      "Epoch 766, Weight = 1.9968700408935547, Bias = 0.023372747004032135, Training Loss = 0.00011013410403393209, Testing Loss = 0.00015665074897697195\n",
      "Epoch 767, Weight = 1.9968823194503784, Bias = 0.02328088879585266, Training Loss = 0.0001092644888558425, Testing Loss = 0.00015542066103080288\n",
      "Epoch 768, Weight = 1.9968944787979126, Bias = 0.023189391940832138, Training Loss = 0.00010840879258466884, Testing Loss = 0.00015419541887240484\n",
      "Epoch 769, Weight = 1.9969067573547363, Bias = 0.02309826761484146, Training Loss = 0.00010755877883639187, Testing Loss = 0.00015299183723982424\n",
      "Epoch 770, Weight = 1.9969189167022705, Bias = 0.023007499054074287, Training Loss = 0.00010671656491467729, Testing Loss = 0.00015179297770373523\n",
      "Epoch 771, Weight = 1.9969309568405151, Bias = 0.02291707508265972, Training Loss = 0.0001058734196703881, Testing Loss = 0.00015059883298818022\n",
      "Epoch 772, Weight = 1.9969431161880493, Bias = 0.02282702922821045, Training Loss = 0.00010504820966161788, Testing Loss = 0.0001494224270572886\n",
      "Epoch 773, Weight = 1.9969550371170044, Bias = 0.02273731306195259, Training Loss = 0.00010422203195048496, Testing Loss = 0.0001482441512052901\n",
      "Epoch 774, Weight = 1.9969669580459595, Bias = 0.022647956386208534, Training Loss = 0.00010340493463445455, Testing Loss = 0.00014708056187373586\n",
      "Epoch 775, Weight = 1.996978998184204, Bias = 0.022558966651558876, Training Loss = 0.00010259573173243552, Testing Loss = 0.0001459408667869866\n",
      "Epoch 776, Weight = 1.9969907999038696, Bias = 0.02247031033039093, Training Loss = 0.00010179405217058957, Testing Loss = 0.00014478283264907077\n",
      "Epoch 777, Weight = 1.9970026016235352, Bias = 0.02238200604915619, Training Loss = 0.00010099060455104336, Testing Loss = 0.00014363932132255286\n",
      "Epoch 778, Weight = 1.9970144033432007, Bias = 0.0222940556704998, Training Loss = 0.00010019597539212555, Testing Loss = 0.00014252293476602063\n",
      "Epoch 779, Weight = 1.9970260858535767, Bias = 0.022206440567970276, Training Loss = 9.941124153556302e-05, Testing Loss = 0.0001414010694134049\n",
      "Epoch 780, Weight = 1.9970378875732422, Bias = 0.022119181230664253, Training Loss = 9.863139712251723e-05, Testing Loss = 0.00014029974408913404\n",
      "Epoch 781, Weight = 1.9970494508743286, Bias = 0.022032245993614197, Training Loss = 9.785900329006836e-05, Testing Loss = 0.00013919296907261014\n",
      "Epoch 782, Weight = 1.9970611333847046, Bias = 0.021945668384432793, Training Loss = 9.70888213487342e-05, Testing Loss = 0.00013810029122396372\n",
      "Epoch 783, Weight = 1.9970725774765015, Bias = 0.021859413012862206, Training Loss = 9.632858564145863e-05, Testing Loss = 0.00013701815259992145\n",
      "Epoch 784, Weight = 1.997084140777588, Bias = 0.021773511543869972, Training Loss = 9.55708819674328e-05, Testing Loss = 0.00013594027404906228\n",
      "Epoch 785, Weight = 1.9970955848693848, Bias = 0.0216879453510046, Training Loss = 9.482285531703383e-05, Testing Loss = 0.00013487284013535827\n",
      "Epoch 786, Weight = 1.9971070289611816, Bias = 0.021602721884846687, Training Loss = 9.407981997355819e-05, Testing Loss = 0.0001338191723334603\n",
      "Epoch 787, Weight = 1.9971184730529785, Bias = 0.021517829969525337, Training Loss = 9.33434785110876e-05, Testing Loss = 0.00013277578182169236\n",
      "Epoch 788, Weight = 1.9971296787261963, Bias = 0.021433256566524506, Training Loss = 9.260854858439416e-05, Testing Loss = 0.00013172698163543828\n",
      "Epoch 789, Weight = 1.9971410036087036, Bias = 0.02134903520345688, Training Loss = 9.188616240862757e-05, Testing Loss = 0.00013070124623482116\n",
      "Epoch 790, Weight = 1.9971522092819214, Bias = 0.021265128627419472, Training Loss = 9.116275032283738e-05, Testing Loss = 0.0001296701011597179\n",
      "Epoch 791, Weight = 1.9971634149551392, Bias = 0.021181568503379822, Training Loss = 9.045003389474005e-05, Testing Loss = 0.00012865513417636976\n",
      "Epoch 792, Weight = 1.997174620628357, Bias = 0.021098338067531586, Training Loss = 8.973837975645438e-05, Testing Loss = 0.00012764747225446627\n",
      "Epoch 793, Weight = 1.9971855878829956, Bias = 0.021015414968132973, Training Loss = 8.90318478923291e-05, Testing Loss = 0.00012664045789279044\n",
      "Epoch 794, Weight = 1.9971967935562134, Bias = 0.020932842046022415, Training Loss = 8.833713218336925e-05, Testing Loss = 0.0001256526738870889\n",
      "Epoch 795, Weight = 1.997207760810852, Bias = 0.020850565284490585, Training Loss = 8.764339872868732e-05, Testing Loss = 0.0001246687606908381\n",
      "Epoch 796, Weight = 1.9972186088562012, Bias = 0.02076861821115017, Training Loss = 8.695129508851096e-05, Testing Loss = 0.00012367359158815816\n",
      "Epoch 797, Weight = 1.9972295761108398, Bias = 0.020687012001872063, Training Loss = 8.626989438198507e-05, Testing Loss = 0.00012271253217477351\n",
      "Epoch 798, Weight = 1.997240424156189, Bias = 0.020605718716979027, Training Loss = 8.55968683026731e-05, Testing Loss = 0.00012174021685495973\n",
      "Epoch 799, Weight = 1.9972513914108276, Bias = 0.020524751394987106, Training Loss = 8.492758934153244e-05, Testing Loss = 0.00012079842417733744\n",
      "Epoch 800, Weight = 1.9972622394561768, Bias = 0.02044409140944481, Training Loss = 8.426118438364938e-05, Testing Loss = 0.00011985445598838851\n",
      "Epoch 801, Weight = 1.9972728490829468, Bias = 0.020363736897706985, Training Loss = 8.3595747128129e-05, Testing Loss = 0.00011889936286024749\n",
      "Epoch 802, Weight = 1.997283697128296, Bias = 0.020283721387386322, Training Loss = 8.294365397887304e-05, Testing Loss = 0.00011797762999776751\n",
      "Epoch 803, Weight = 1.997294306755066, Bias = 0.020203998312354088, Training Loss = 8.228811930166557e-05, Testing Loss = 0.00011705053111654706\n",
      "Epoch 804, Weight = 1.9973050355911255, Bias = 0.020124606788158417, Training Loss = 8.164341852534562e-05, Testing Loss = 0.00011614174582064152\n",
      "Epoch 805, Weight = 1.997315526008606, Bias = 0.020045507699251175, Training Loss = 8.100492414087057e-05, Testing Loss = 0.00011522190470714122\n",
      "Epoch 806, Weight = 1.9973260164260864, Bias = 0.01996673084795475, Training Loss = 8.03674483904615e-05, Testing Loss = 0.00011431142047513276\n",
      "Epoch 807, Weight = 1.997336506843567, Bias = 0.019888268783688545, Training Loss = 7.974198524607345e-05, Testing Loss = 0.00011341902063577436\n",
      "Epoch 808, Weight = 1.997347116470337, Bias = 0.01981012523174286, Training Loss = 7.911432476248592e-05, Testing Loss = 0.00011253577031311579\n",
      "Epoch 809, Weight = 1.9973576068878174, Bias = 0.019732274115085602, Training Loss = 7.849602843634784e-05, Testing Loss = 0.0001116647181333974\n",
      "Epoch 810, Weight = 1.9973678588867188, Bias = 0.019654715433716774, Training Loss = 7.788172661093995e-05, Testing Loss = 0.0001107684220187366\n",
      "Epoch 811, Weight = 1.9973782300949097, Bias = 0.019577478989958763, Training Loss = 7.726532203378156e-05, Testing Loss = 0.00010990424198098481\n",
      "Epoch 812, Weight = 1.9973886013031006, Bias = 0.019500551745295525, Training Loss = 7.666054443689063e-05, Testing Loss = 0.00010904901137109846\n",
      "Epoch 813, Weight = 1.9973987340927124, Bias = 0.01942390576004982, Training Loss = 7.605928112752736e-05, Testing Loss = 0.00010818298324011266\n",
      "Epoch 814, Weight = 1.9974089860916138, Bias = 0.019347578287124634, Training Loss = 7.545918197138235e-05, Testing Loss = 0.0001073400053428486\n",
      "Epoch 815, Weight = 1.9974191188812256, Bias = 0.019271546974778175, Training Loss = 7.486819959012792e-05, Testing Loss = 0.00010648933675838634\n",
      "Epoch 816, Weight = 1.9974292516708374, Bias = 0.019195817410945892, Training Loss = 7.428275421261787e-05, Testing Loss = 0.0001056584733305499\n",
      "Epoch 817, Weight = 1.9974393844604492, Bias = 0.019120391458272934, Training Loss = 7.37010850571096e-05, Testing Loss = 0.00010482540892553516\n",
      "Epoch 818, Weight = 1.9974493980407715, Bias = 0.019045252352952957, Training Loss = 7.311980152735487e-05, Testing Loss = 0.00010400108294561505\n",
      "Epoch 819, Weight = 1.9974595308303833, Bias = 0.018970420584082603, Training Loss = 7.254941738210618e-05, Testing Loss = 0.0001031938154483214\n",
      "Epoch 820, Weight = 1.997469425201416, Bias = 0.018895862624049187, Training Loss = 7.197894592536613e-05, Testing Loss = 0.00010237891547149047\n",
      "Epoch 821, Weight = 1.9974794387817383, Bias = 0.01882161572575569, Training Loss = 7.141684181988239e-05, Testing Loss = 0.00010158334771404043\n",
      "Epoch 822, Weight = 1.997489333152771, Bias = 0.01874765194952488, Training Loss = 7.085777906468138e-05, Testing Loss = 0.00010078553896164522\n",
      "Epoch 823, Weight = 1.9974992275238037, Bias = 0.018673984333872795, Training Loss = 7.030024426057935e-05, Testing Loss = 9.999087342293933e-05\n",
      "Epoch 824, Weight = 1.9975090026855469, Bias = 0.018600594252347946, Training Loss = 6.974471034482121e-05, Testing Loss = 9.920466254698113e-05\n",
      "Epoch 825, Weight = 1.9975188970565796, Bias = 0.018527504056692123, Training Loss = 6.920179293956608e-05, Testing Loss = 9.843504449236207e-05\n",
      "Epoch 826, Weight = 1.9975285530090332, Bias = 0.018454687669873238, Training Loss = 6.865442264825106e-05, Testing Loss = 9.765498180058785e-05\n",
      "Epoch 827, Weight = 1.9975383281707764, Bias = 0.01838216930627823, Training Loss = 6.81192905176431e-05, Testing Loss = 9.689140642876737e-05\n",
      "Epoch 828, Weight = 1.99754798412323, Bias = 0.018309924751520157, Training Loss = 6.758271047146991e-05, Testing Loss = 9.613605288905092e-05\n",
      "Epoch 829, Weight = 1.9975576400756836, Bias = 0.018237972632050514, Training Loss = 6.705347186652943e-05, Testing Loss = 9.538365702610463e-05\n",
      "Epoch 830, Weight = 1.9975671768188477, Bias = 0.01816629245877266, Training Loss = 6.652959564235061e-05, Testing Loss = 9.46290347201284e-05\n",
      "Epoch 831, Weight = 1.9975768327713013, Bias = 0.018094908446073532, Training Loss = 6.60104415146634e-05, Testing Loss = 9.38928897085134e-05\n",
      "Epoch 832, Weight = 1.9975862503051758, Bias = 0.018023785203695297, Training Loss = 6.548942474182695e-05, Testing Loss = 9.314934141002595e-05\n",
      "Epoch 833, Weight = 1.9975957870483398, Bias = 0.01795296184718609, Training Loss = 6.497535650851205e-05, Testing Loss = 9.242181477020495e-05\n",
      "Epoch 834, Weight = 1.9976052045822144, Bias = 0.01788240112364292, Training Loss = 6.446320912800729e-05, Testing Loss = 9.16971439437475e-05\n",
      "Epoch 835, Weight = 1.9976146221160889, Bias = 0.017812127247452736, Training Loss = 6.395973468897864e-05, Testing Loss = 9.097252041101456e-05\n",
      "Epoch 836, Weight = 1.9976240396499634, Bias = 0.017742132768034935, Training Loss = 6.345676956698298e-05, Testing Loss = 9.026368206832558e-05\n",
      "Epoch 837, Weight = 1.9976333379745483, Bias = 0.017672406509518623, Training Loss = 6.296037463471293e-05, Testing Loss = 8.955258090281859e-05\n",
      "Epoch 838, Weight = 1.9976426362991333, Bias = 0.017602957785129547, Training Loss = 6.24687600065954e-05, Testing Loss = 8.885710849426687e-05\n",
      "Epoch 839, Weight = 1.9976518154144287, Bias = 0.01753377728164196, Training Loss = 6.197750917635858e-05, Testing Loss = 8.81438136275392e-05\n",
      "Epoch 840, Weight = 1.9976611137390137, Bias = 0.017464885488152504, Training Loss = 6.14882301306352e-05, Testing Loss = 8.746380626689643e-05\n",
      "Epoch 841, Weight = 1.997670292854309, Bias = 0.017396248877048492, Training Loss = 6.100633618189022e-05, Testing Loss = 8.67814669618383e-05\n",
      "Epoch 842, Weight = 1.9976794719696045, Bias = 0.01732788421213627, Training Loss = 6.0528349422384053e-05, Testing Loss = 8.609686119598337e-05\n",
      "Epoch 843, Weight = 1.9976885318756104, Bias = 0.017259785905480385, Training Loss = 6.0054819186916575e-05, Testing Loss = 8.5417166701518e-05\n",
      "Epoch 844, Weight = 1.9976977109909058, Bias = 0.017191970720887184, Training Loss = 5.9585345297819003e-05, Testing Loss = 8.475539289065637e-05\n",
      "Epoch 845, Weight = 1.9977067708969116, Bias = 0.01712440699338913, Training Loss = 5.91167263337411e-05, Testing Loss = 8.408860594499856e-05\n",
      "Epoch 846, Weight = 1.9977158308029175, Bias = 0.017057109624147415, Training Loss = 5.8653207815950736e-05, Testing Loss = 8.342932414961979e-05\n",
      "Epoch 847, Weight = 1.9977247714996338, Bias = 0.016990065574645996, Training Loss = 5.8193600125378e-05, Testing Loss = 8.277748202090152e-05\n",
      "Epoch 848, Weight = 1.99773371219635, Bias = 0.016923293471336365, Training Loss = 5.77356549911201e-05, Testing Loss = 8.213086039177142e-05\n",
      "Epoch 849, Weight = 1.9977425336837769, Bias = 0.016856785863637924, Training Loss = 5.728230462409556e-05, Testing Loss = 8.147449989337474e-05\n",
      "Epoch 850, Weight = 1.9977514743804932, Bias = 0.016790542751550674, Training Loss = 5.683519702870399e-05, Testing Loss = 8.08425793366041e-05\n",
      "Epoch 851, Weight = 1.99776029586792, Bias = 0.016724558547139168, Training Loss = 5.638963921228424e-05, Testing Loss = 8.020834866329096e-05\n",
      "Epoch 852, Weight = 1.9977691173553467, Bias = 0.016658833250403404, Training Loss = 5.594758840743452e-05, Testing Loss = 7.957661000546068e-05\n",
      "Epoch 853, Weight = 1.9977778196334839, Bias = 0.016593364998698235, Training Loss = 5.5507069191662595e-05, Testing Loss = 7.89521072874777e-05\n",
      "Epoch 854, Weight = 1.9977866411209106, Bias = 0.016528166830539703, Training Loss = 5.507055175257847e-05, Testing Loss = 7.834209827706218e-05\n",
      "Epoch 855, Weight = 1.9977952241897583, Bias = 0.016463197767734528, Training Loss = 5.4638781875837594e-05, Testing Loss = 7.771517630317248e-05\n",
      "Epoch 856, Weight = 1.9978039264678955, Bias = 0.016398504376411438, Training Loss = 5.421212699729949e-05, Testing Loss = 7.710997306276113e-05\n",
      "Epoch 857, Weight = 1.9978125095367432, Bias = 0.016334058716893196, Training Loss = 5.3783915063831955e-05, Testing Loss = 7.650713450857438e-05\n",
      "Epoch 858, Weight = 1.9978210926055908, Bias = 0.016269870102405548, Training Loss = 5.336537287803367e-05, Testing Loss = 7.58994574425742e-05\n",
      "Epoch 859, Weight = 1.9978296756744385, Bias = 0.016205942258238792, Training Loss = 5.294570291880518e-05, Testing Loss = 7.530600305472035e-05\n",
      "Epoch 860, Weight = 1.9978382587432861, Bias = 0.016142260283231735, Training Loss = 5.2529325330397114e-05, Testing Loss = 7.471948265447281e-05\n",
      "Epoch 861, Weight = 1.9978468418121338, Bias = 0.016078827902674675, Training Loss = 5.2119441534159705e-05, Testing Loss = 7.414237552438863e-05\n",
      "Epoch 862, Weight = 1.9978551864624023, Bias = 0.01601562835276127, Training Loss = 5.1710547268157825e-05, Testing Loss = 7.355127490882296e-05\n",
      "Epoch 863, Weight = 1.997863531112671, Bias = 0.015952685847878456, Training Loss = 5.130258796270937e-05, Testing Loss = 7.296709009096958e-05\n",
      "Epoch 864, Weight = 1.997871994972229, Bias = 0.015890002250671387, Training Loss = 5.090002377983183e-05, Testing Loss = 7.239883416332304e-05\n",
      "Epoch 865, Weight = 1.9978803396224976, Bias = 0.015827560797333717, Training Loss = 5.050196705269627e-05, Testing Loss = 7.18307765055215e-05\n",
      "Epoch 866, Weight = 1.9978888034820557, Bias = 0.015765374526381493, Training Loss = 5.0105816626455635e-05, Testing Loss = 7.127394928829744e-05\n",
      "Epoch 867, Weight = 1.9978970289230347, Bias = 0.015703409910202026, Training Loss = 4.9711743486113846e-05, Testing Loss = 7.071033360261936e-05\n",
      "Epoch 868, Weight = 1.9979053735733032, Bias = 0.015641704201698303, Training Loss = 4.932319279760122e-05, Testing Loss = 7.016233939793892e-05\n",
      "Epoch 869, Weight = 1.9979134798049927, Bias = 0.015580220147967339, Training Loss = 4.893795994576067e-05, Testing Loss = 6.960758582863491e-05\n",
      "Epoch 870, Weight = 1.9979215860366821, Bias = 0.01551898755133152, Training Loss = 4.8550282372161746e-05, Testing Loss = 6.905258851475082e-05\n",
      "Epoch 871, Weight = 1.9979299306869507, Bias = 0.015458020381629467, Training Loss = 4.81734678032808e-05, Testing Loss = 6.851791295048315e-05\n",
      "Epoch 872, Weight = 1.9979380369186401, Bias = 0.015397272072732449, Training Loss = 4.7795216232771054e-05, Testing Loss = 6.798092363169417e-05\n",
      "Epoch 873, Weight = 1.9979461431503296, Bias = 0.01533676590770483, Training Loss = 4.74176267744042e-05, Testing Loss = 6.744800339220092e-05\n",
      "Epoch 874, Weight = 1.9979541301727295, Bias = 0.015276486985385418, Training Loss = 4.7046451072674245e-05, Testing Loss = 6.691523049084935e-05\n",
      "Epoch 875, Weight = 1.997962236404419, Bias = 0.015216462314128876, Training Loss = 4.667929169954732e-05, Testing Loss = 6.639759158133529e-05\n",
      "Epoch 876, Weight = 1.9979702234268188, Bias = 0.015156658366322517, Training Loss = 4.631116462405771e-05, Testing Loss = 6.587092866539024e-05\n",
      "Epoch 877, Weight = 1.9979783296585083, Bias = 0.01509710494428873, Training Loss = 4.5950560888741165e-05, Testing Loss = 6.536403816426173e-05\n",
      "Epoch 878, Weight = 1.9979861974716187, Bias = 0.01503776479512453, Training Loss = 4.558624277706258e-05, Testing Loss = 6.484386722149793e-05\n",
      "Epoch 879, Weight = 1.997994065284729, Bias = 0.014978666789829731, Training Loss = 4.522932431427762e-05, Testing Loss = 6.433859380194917e-05\n",
      "Epoch 880, Weight = 1.998002052307129, Bias = 0.014919809997081757, Training Loss = 4.487582918955013e-05, Testing Loss = 6.383764412021264e-05\n",
      "Epoch 881, Weight = 1.9980098009109497, Bias = 0.014861168339848518, Training Loss = 4.452581924851984e-05, Testing Loss = 6.333207420539111e-05\n",
      "Epoch 882, Weight = 1.9980175495147705, Bias = 0.014802761375904083, Training Loss = 4.4172855268698186e-05, Testing Loss = 6.283273251028731e-05\n",
      "Epoch 883, Weight = 1.9980254173278809, Bias = 0.014744595624506474, Training Loss = 4.382819315651432e-05, Testing Loss = 6.234190004761331e-05\n",
      "Epoch 884, Weight = 1.9980331659317017, Bias = 0.014686652459204197, Training Loss = 4.348498987383209e-05, Testing Loss = 6.185299207572825e-05\n",
      "Epoch 885, Weight = 1.9980409145355225, Bias = 0.014628943055868149, Training Loss = 4.314420948503539e-05, Testing Loss = 6.136600859463215e-05\n",
      "Epoch 886, Weight = 1.9980485439300537, Bias = 0.014571447856724262, Training Loss = 4.2803243559319526e-05, Testing Loss = 6.0878655858687125e-05\n",
      "Epoch 887, Weight = 1.9980562925338745, Bias = 0.014514192007482052, Training Loss = 4.2466526792850345e-05, Testing Loss = 6.0406095144571736e-05\n",
      "Epoch 888, Weight = 1.9980639219284058, Bias = 0.0144571578130126, Training Loss = 4.213432112010196e-05, Testing Loss = 5.99330996919889e-05\n",
      "Epoch 889, Weight = 1.998071551322937, Bias = 0.014400351792573929, Training Loss = 4.1803523345151916e-05, Testing Loss = 5.946196324657649e-05\n",
      "Epoch 890, Weight = 1.9980791807174683, Bias = 0.014343762770295143, Training Loss = 4.147781146457419e-05, Testing Loss = 5.899903771933168e-05\n",
      "Epoch 891, Weight = 1.99808669090271, Bias = 0.014287388883531094, Training Loss = 4.1155359213007614e-05, Testing Loss = 5.8531597460387275e-05\n",
      "Epoch 892, Weight = 1.9980942010879517, Bias = 0.014231238514184952, Training Loss = 4.0826809708960354e-05, Testing Loss = 5.807637353427708e-05\n",
      "Epoch 893, Weight = 1.9981017112731934, Bias = 0.014175309799611568, Training Loss = 4.051200085086748e-05, Testing Loss = 5.762293039879296e-05\n",
      "Epoch 894, Weight = 1.9981091022491455, Bias = 0.014119592495262623, Training Loss = 4.019049083581194e-05, Testing Loss = 5.7165007092407905e-05\n",
      "Epoch 895, Weight = 1.9981164932250977, Bias = 0.014064108021557331, Training Loss = 3.987421587225981e-05, Testing Loss = 5.6715140090091154e-05\n",
      "Epoch 896, Weight = 1.9981240034103394, Bias = 0.014008847996592522, Training Loss = 3.956223008572124e-05, Testing Loss = 5.627725113299675e-05\n",
      "Epoch 897, Weight = 1.9981313943862915, Bias = 0.013953793793916702, Training Loss = 3.9250797271961346e-05, Testing Loss = 5.583487836702261e-05\n",
      "Epoch 898, Weight = 1.998138666152954, Bias = 0.013898945413529873, Training Loss = 3.8944930565776303e-05, Testing Loss = 5.5394251830875874e-05\n",
      "Epoch 899, Weight = 1.9981460571289062, Bias = 0.013844328932464123, Training Loss = 3.863943129545078e-05, Testing Loss = 5.496545054484159e-05\n",
      "Epoch 900, Weight = 1.9981533288955688, Bias = 0.013789917342364788, Training Loss = 3.8337951991707087e-05, Testing Loss = 5.4532209105673246e-05\n",
      "Epoch 901, Weight = 1.9981606006622314, Bias = 0.01373571902513504, Training Loss = 3.803610161412507e-05, Testing Loss = 5.41067638550885e-05\n",
      "Epoch 902, Weight = 1.9981677532196045, Bias = 0.013681734912097454, Training Loss = 3.7739071558462456e-05, Testing Loss = 5.3673022193834186e-05\n",
      "Epoch 903, Weight = 1.998175024986267, Bias = 0.013627976179122925, Training Loss = 3.744087371160276e-05, Testing Loss = 5.325483652995899e-05\n",
      "Epoch 904, Weight = 1.9981821775436401, Bias = 0.013574411161243916, Training Loss = 3.714573540491983e-05, Testing Loss = 5.283828795654699e-05\n",
      "Epoch 905, Weight = 1.9981893301010132, Bias = 0.013521064072847366, Training Loss = 3.685662159114145e-05, Testing Loss = 5.242336919764057e-05\n",
      "Epoch 906, Weight = 1.9981963634490967, Bias = 0.013467920944094658, Training Loss = 3.656639455584809e-05, Testing Loss = 5.2006249461555853e-05\n",
      "Epoch 907, Weight = 1.9982035160064697, Bias = 0.013415003195405006, Training Loss = 3.627964179031551e-05, Testing Loss = 5.160821456229314e-05\n",
      "Epoch 908, Weight = 1.9982105493545532, Bias = 0.013362281955778599, Training Loss = 3.5997654777020216e-05, Testing Loss = 5.120197783980984e-05\n",
      "Epoch 909, Weight = 1.9982175827026367, Bias = 0.013309773989021778, Training Loss = 3.571153138182126e-05, Testing Loss = 5.079734910395928e-05\n",
      "Epoch 910, Weight = 1.9982246160507202, Bias = 0.013257469981908798, Training Loss = 3.543239290593192e-05, Testing Loss = 5.040019459556788e-05\n",
      "Epoch 911, Weight = 1.9982315301895142, Bias = 0.01320536620914936, Training Loss = 3.515173739288002e-05, Testing Loss = 5.0002516218228266e-05\n",
      "Epoch 912, Weight = 1.9982385635375977, Bias = 0.013153480365872383, Training Loss = 3.488130460027605e-05, Testing Loss = 4.961224112776108e-05\n",
      "Epoch 913, Weight = 1.9982454776763916, Bias = 0.01310179103165865, Training Loss = 3.460649531916715e-05, Testing Loss = 4.922349035041407e-05\n",
      "Epoch 914, Weight = 1.9982523918151855, Bias = 0.013050301931798458, Training Loss = 3.4334356314502656e-05, Testing Loss = 4.883627298113424e-05\n",
      "Epoch 915, Weight = 1.99825918674469, Bias = 0.01299900934100151, Training Loss = 3.406322866794653e-05, Testing Loss = 4.8454290663357824e-05\n",
      "Epoch 916, Weight = 1.9982661008834839, Bias = 0.012947933748364449, Training Loss = 3.37968158419244e-05, Testing Loss = 4.807380901183933e-05\n",
      "Epoch 917, Weight = 1.9982728958129883, Bias = 0.012897051870822906, Training Loss = 3.3534419344505295e-05, Testing Loss = 4.770053783431649e-05\n",
      "Epoch 918, Weight = 1.9982795715332031, Bias = 0.012846359051764011, Training Loss = 3.32697200065013e-05, Testing Loss = 4.731734406959731e-05\n",
      "Epoch 919, Weight = 1.998286485671997, Bias = 0.012795887887477875, Training Loss = 3.300897151348181e-05, Testing Loss = 4.695432653534226e-05\n",
      "Epoch 920, Weight = 1.998293161392212, Bias = 0.012745591811835766, Training Loss = 3.2748117519076914e-05, Testing Loss = 4.658543548430316e-05\n",
      "Epoch 921, Weight = 1.9982998371124268, Bias = 0.012695502489805222, Training Loss = 3.2494484912604094e-05, Testing Loss = 4.6215998736443e-05\n",
      "Epoch 922, Weight = 1.9983065128326416, Bias = 0.01264561340212822, Training Loss = 3.2237487175734714e-05, Testing Loss = 4.585723945638165e-05\n",
      "Epoch 923, Weight = 1.9983131885528564, Bias = 0.012595918029546738, Training Loss = 3.198607009835541e-05, Testing Loss = 4.5499878979171626e-05\n",
      "Epoch 924, Weight = 1.9983197450637817, Bias = 0.012546411715447903, Training Loss = 3.173440563841723e-05, Testing Loss = 4.513478234002832e-05\n",
      "Epoch 925, Weight = 1.998326301574707, Bias = 0.012497106567025185, Training Loss = 3.148395262542181e-05, Testing Loss = 4.477668699109927e-05\n",
      "Epoch 926, Weight = 1.9983329772949219, Bias = 0.012448012828826904, Training Loss = 3.1238490919349715e-05, Testing Loss = 4.4432632421376184e-05\n",
      "Epoch 927, Weight = 1.9983395338058472, Bias = 0.012399096041917801, Training Loss = 3.0994338885648176e-05, Testing Loss = 4.408441418490838e-05\n",
      "Epoch 928, Weight = 1.9983460903167725, Bias = 0.012350374832749367, Training Loss = 3.074808410019614e-05, Testing Loss = 4.373756564746145e-05\n",
      "Epoch 929, Weight = 1.9983525276184082, Bias = 0.012301839888095856, Training Loss = 3.050823215744458e-05, Testing Loss = 4.339208680903539e-05\n",
      "Epoch 930, Weight = 1.9983590841293335, Bias = 0.012253504246473312, Training Loss = 3.0269144190242514e-05, Testing Loss = 4.305340553401038e-05\n",
      "Epoch 931, Weight = 1.9983655214309692, Bias = 0.012205344624817371, Training Loss = 3.0033317671041004e-05, Testing Loss = 4.271953002898954e-05\n",
      "Epoch 932, Weight = 1.9983718395233154, Bias = 0.012157373130321503, Training Loss = 2.9795410227961838e-05, Testing Loss = 4.237810389895458e-05\n",
      "Epoch 933, Weight = 1.9983782768249512, Bias = 0.012109605595469475, Training Loss = 2.9562848794739693e-05, Testing Loss = 4.205031837045681e-05\n",
      "Epoch 934, Weight = 1.9983845949172974, Bias = 0.01206201408058405, Training Loss = 2.932998540927656e-05, Testing Loss = 4.17150240537012e-05\n",
      "Epoch 935, Weight = 1.9983909130096436, Bias = 0.012014616280794144, Training Loss = 2.9099439416313544e-05, Testing Loss = 4.138296208111569e-05\n",
      "Epoch 936, Weight = 1.9983973503112793, Bias = 0.01196742057800293, Training Loss = 2.88719056698028e-05, Testing Loss = 4.106776759726927e-05\n",
      "Epoch 937, Weight = 1.9984036684036255, Bias = 0.011920386925339699, Training Loss = 2.8647209546761587e-05, Testing Loss = 4.07485003961483e-05\n",
      "Epoch 938, Weight = 1.9984098672866821, Bias = 0.011873534880578518, Training Loss = 2.8418544388841838e-05, Testing Loss = 4.042709042550996e-05\n",
      "Epoch 939, Weight = 1.9984161853790283, Bias = 0.011826884932816029, Training Loss = 2.819843211909756e-05, Testing Loss = 4.011032797279768e-05\n",
      "Epoch 940, Weight = 1.998422384262085, Bias = 0.011780403554439545, Training Loss = 2.7976315323030576e-05, Testing Loss = 3.979330722359009e-05\n",
      "Epoch 941, Weight = 1.9984285831451416, Bias = 0.011734108440577984, Training Loss = 2.7758456781157292e-05, Testing Loss = 3.9482387364842e-05\n",
      "Epoch 942, Weight = 1.9984347820281982, Bias = 0.011687998659908772, Training Loss = 2.7540227165445685e-05, Testing Loss = 3.9174530684249476e-05\n",
      "Epoch 943, Weight = 1.9984408617019653, Bias = 0.011642062105238438, Training Loss = 2.7324293114361353e-05, Testing Loss = 3.886272315867245e-05\n",
      "Epoch 944, Weight = 1.9984469413757324, Bias = 0.011596308089792728, Training Loss = 2.7109899747301824e-05, Testing Loss = 3.855729664792307e-05\n",
      "Epoch 945, Weight = 1.9984530210494995, Bias = 0.011550740338861942, Training Loss = 2.689563734747935e-05, Testing Loss = 3.8251255318755284e-05\n",
      "Epoch 946, Weight = 1.9984592199325562, Bias = 0.011505366303026676, Training Loss = 2.6686688215704635e-05, Testing Loss = 3.795990414801054e-05\n",
      "Epoch 947, Weight = 1.9984652996063232, Bias = 0.011460153385996819, Training Loss = 2.6476500352146104e-05, Testing Loss = 3.766132067539729e-05\n",
      "Epoch 948, Weight = 1.9984713792800903, Bias = 0.011415118351578712, Training Loss = 2.6270477974321693e-05, Testing Loss = 3.7367173717939295e-05\n",
      "Epoch 949, Weight = 1.9984772205352783, Bias = 0.011370241641998291, Training Loss = 2.6063065888592973e-05, Testing Loss = 3.7070936741656624e-05\n",
      "Epoch 950, Weight = 1.9984833002090454, Bias = 0.011325567029416561, Training Loss = 2.585982838354539e-05, Testing Loss = 3.677910899568815e-05\n",
      "Epoch 951, Weight = 1.998489260673523, Bias = 0.011281058192253113, Training Loss = 2.565602699178271e-05, Testing Loss = 3.649342943390366e-05\n",
      "Epoch 952, Weight = 1.9984952211380005, Bias = 0.011236726306378841, Training Loss = 2.5454215574427508e-05, Testing Loss = 3.6207093216944486e-05\n",
      "Epoch 953, Weight = 1.9985010623931885, Bias = 0.011192557401955128, Training Loss = 2.5255998480133712e-05, Testing Loss = 3.591869244701229e-05\n",
      "Epoch 954, Weight = 1.998507022857666, Bias = 0.011148583143949509, Training Loss = 2.5056840968318284e-05, Testing Loss = 3.563956306606997e-05\n",
      "Epoch 955, Weight = 1.998512864112854, Bias = 0.011104774661362171, Training Loss = 2.486090306774713e-05, Testing Loss = 3.536151962180156e-05\n",
      "Epoch 956, Weight = 1.998518705368042, Bias = 0.011061138473451138, Training Loss = 2.4665023374836892e-05, Testing Loss = 3.5079669032711536e-05\n",
      "Epoch 957, Weight = 1.99852454662323, Bias = 0.01101767923682928, Training Loss = 2.44717848545406e-05, Testing Loss = 3.480696614133194e-05\n",
      "Epoch 958, Weight = 1.998530387878418, Bias = 0.01097438670694828, Training Loss = 2.428102379781194e-05, Testing Loss = 3.453532735875342e-05\n",
      "Epoch 959, Weight = 1.9985361099243164, Bias = 0.01093125157058239, Training Loss = 2.408741602266673e-05, Testing Loss = 3.42616349371383e-05\n",
      "Epoch 960, Weight = 1.9985419511795044, Bias = 0.010888299904763699, Training Loss = 2.3900372980278917e-05, Testing Loss = 3.4000066079897806e-05\n",
      "Epoch 961, Weight = 1.9985475540161133, Bias = 0.010845494456589222, Training Loss = 2.3711148969596252e-05, Testing Loss = 3.372679748281371e-05\n",
      "Epoch 962, Weight = 1.9985533952713013, Bias = 0.010802884586155415, Training Loss = 2.352749834244605e-05, Testing Loss = 3.346728044562042e-05\n",
      "Epoch 963, Weight = 1.9985588788986206, Bias = 0.010760410688817501, Training Loss = 2.3342208805843256e-05, Testing Loss = 3.3197862649103627e-05\n",
      "Epoch 964, Weight = 1.998564600944519, Bias = 0.01071813702583313, Training Loss = 2.3158167095971294e-05, Testing Loss = 3.2938703952822834e-05\n",
      "Epoch 965, Weight = 1.9985703229904175, Bias = 0.010676027275621891, Training Loss = 2.2979134882916696e-05, Testing Loss = 3.26822428178275e-05\n",
      "Epoch 966, Weight = 1.9985759258270264, Bias = 0.010634070262312889, Training Loss = 2.2798956706537865e-05, Testing Loss = 3.2426785764982924e-05\n",
      "Epoch 967, Weight = 1.9985815286636353, Bias = 0.010592279024422169, Training Loss = 2.2619675291934982e-05, Testing Loss = 3.217368066543713e-05\n",
      "Epoch 968, Weight = 1.9985871315002441, Bias = 0.010550652630627155, Training Loss = 2.2442362023866735e-05, Testing Loss = 3.192022268194705e-05\n",
      "Epoch 969, Weight = 1.9985926151275635, Bias = 0.010509185492992401, Training Loss = 2.226424840046093e-05, Testing Loss = 3.167076283716597e-05\n",
      "Epoch 970, Weight = 1.9985980987548828, Bias = 0.010467884130775928, Training Loss = 2.2090736820246093e-05, Testing Loss = 3.141764864267316e-05\n",
      "Epoch 971, Weight = 1.9986037015914917, Bias = 0.010426759719848633, Training Loss = 2.1917034246143885e-05, Testing Loss = 3.117775486316532e-05\n",
      "Epoch 972, Weight = 1.998609185218811, Bias = 0.01038578525185585, Training Loss = 2.1744141122326255e-05, Testing Loss = 3.093418308708351e-05\n",
      "Epoch 973, Weight = 1.9986146688461304, Bias = 0.010344973765313625, Training Loss = 2.15751861105673e-05, Testing Loss = 3.068861587962601e-05\n",
      "Epoch 974, Weight = 1.9986200332641602, Bias = 0.010304316878318787, Training Loss = 2.1403340724646114e-05, Testing Loss = 3.044696495635435e-05\n",
      "Epoch 975, Weight = 1.9986255168914795, Bias = 0.010263831354677677, Training Loss = 2.1239293346297927e-05, Testing Loss = 3.020627082150895e-05\n",
      "Epoch 976, Weight = 1.9986310005187988, Bias = 0.01022349949926138, Training Loss = 2.107112595695071e-05, Testing Loss = 2.9973974960739724e-05\n",
      "Epoch 977, Weight = 1.9986363649368286, Bias = 0.01018331479281187, Training Loss = 2.090584166580811e-05, Testing Loss = 2.973806476802565e-05\n",
      "Epoch 978, Weight = 1.9986416101455688, Bias = 0.0101432790979743, Training Loss = 2.0740280888276175e-05, Testing Loss = 2.9500193704734556e-05\n",
      "Epoch 979, Weight = 1.9986469745635986, Bias = 0.010103424079716206, Training Loss = 2.057859455817379e-05, Testing Loss = 2.9270633604028262e-05\n",
      "Epoch 980, Weight = 1.9986523389816284, Bias = 0.010063719935715199, Training Loss = 2.0417250198079273e-05, Testing Loss = 2.9041970265097916e-05\n",
      "Epoch 981, Weight = 1.9986575841903687, Bias = 0.01002416666597128, Training Loss = 2.025902722380124e-05, Testing Loss = 2.8814203687943518e-05\n",
      "Epoch 982, Weight = 1.9986628293991089, Bias = 0.009984767064452171, Training Loss = 2.0096873413422145e-05, Testing Loss = 2.8585760446731e-05\n",
      "Epoch 983, Weight = 1.9986681938171387, Bias = 0.009945535100996494, Training Loss = 1.9941369828302413e-05, Testing Loss = 2.8367034246912226e-05\n",
      "Epoch 984, Weight = 1.9986733198165894, Bias = 0.009906437247991562, Training Loss = 1.978470027097501e-05, Testing Loss = 2.8137548724771477e-05\n",
      "Epoch 985, Weight = 1.9986785650253296, Bias = 0.009867507964372635, Training Loss = 1.962922942766454e-05, Testing Loss = 2.7918993509956636e-05\n",
      "Epoch 986, Weight = 1.9986838102340698, Bias = 0.009828729555010796, Training Loss = 1.9475792214507237e-05, Testing Loss = 2.7702839361154474e-05\n",
      "Epoch 987, Weight = 1.99868905544281, Bias = 0.009790105745196342, Training Loss = 1.932289160322398e-05, Testing Loss = 2.748598126345314e-05\n",
      "Epoch 988, Weight = 1.9986940622329712, Bias = 0.009751612320542336, Training Loss = 1.9170689483871683e-05, Testing Loss = 2.726997627178207e-05\n",
      "Epoch 989, Weight = 1.9986991882324219, Bias = 0.009713292121887207, Training Loss = 1.901903669931926e-05, Testing Loss = 2.7052050427300856e-05\n",
      "Epoch 990, Weight = 1.9987043142318726, Bias = 0.009675120934844017, Training Loss = 1.8869359337259084e-05, Testing Loss = 2.684204446268268e-05\n",
      "Epoch 991, Weight = 1.9987093210220337, Bias = 0.009637096896767616, Training Loss = 1.8722112145042047e-05, Testing Loss = 2.662858969415538e-05\n",
      "Epoch 992, Weight = 1.9987144470214844, Bias = 0.009599235840141773, Training Loss = 1.8574781279312447e-05, Testing Loss = 2.6422976588946767e-05\n",
      "Epoch 993, Weight = 1.9987194538116455, Bias = 0.009561510756611824, Training Loss = 1.843037171056494e-05, Testing Loss = 2.621392377477605e-05\n",
      "Epoch 994, Weight = 1.9987245798110962, Bias = 0.00952394399791956, Training Loss = 1.828615859267302e-05, Testing Loss = 2.6009920475189574e-05\n",
      "Epoch 995, Weight = 1.9987295866012573, Bias = 0.009486514143645763, Training Loss = 1.814406095945742e-05, Testing Loss = 2.580671207397245e-05\n",
      "Epoch 996, Weight = 1.9987345933914185, Bias = 0.009449238888919353, Training Loss = 1.799948586267419e-05, Testing Loss = 2.560430220910348e-05\n",
      "Epoch 997, Weight = 1.9987396001815796, Bias = 0.009412103332579136, Training Loss = 1.785866879799869e-05, Testing Loss = 2.5405373889952898e-05\n",
      "Epoch 998, Weight = 1.9987444877624512, Bias = 0.009375106543302536, Training Loss = 1.771727329469286e-05, Testing Loss = 2.5204546545865014e-05\n",
      "Epoch 999, Weight = 1.9987493753433228, Bias = 0.00933825969696045, Training Loss = 1.758034159138333e-05, Testing Loss = 2.500304617569782e-05\n",
      "Epoch 1000, Weight = 1.9987543821334839, Bias = 0.009301568381488323, Training Loss = 1.744176188367419e-05, Testing Loss = 2.4810589820845053e-05\n",
      "\n",
      "***** End of processing *****\n"
     ]
    }
   ],
   "source": [
    "parms = []\n",
    "weight = torch.empty((1,1))\n",
    "bias = torch.empty((1,1))\n",
    "\n",
    "for t in range (epochs):\n",
    "    \n",
    "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "    #    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]}\")\n",
    "        parms.append(param[:2])\n",
    "    \n",
    "    test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "    weight = parms[0]\n",
    "    bias = parms[1]\n",
    "    \n",
    "    print(f\"Epoch {t+1}, Weight = {weight.detach().numpy()[0][0]}, Bias = {bias.detach().numpy()[0]}, Training Loss = {train_loss}, Testing Loss = {test_loss}\")\n",
    "    \n",
    "    writer.add_scalars('Training vs. Test Loss',\n",
    "                            {'Training' : train_loss, 'Test' : test_loss,}, t)\n",
    "    \n",
    "    writer.flush()\n",
    "\n",
    "print(\"\\n***** End of processing *****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbacea1d-2248-4c99-afb8-6995f54ecd61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
